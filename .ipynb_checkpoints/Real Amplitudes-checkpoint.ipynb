{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d093a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew Hayman\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\Andrew Hayman\\PycharmProjects\\Hybrid_Network_Models\\venv\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cca78b",
   "metadata": {},
   "source": [
    "# MNIST Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8512c0",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4405ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from MNIST dataset \n",
    "training_data = torchvision.datasets.MNIST(\"root\", train=True, download=True, transform=ToTensor())\n",
    "testing_data = torchvision.datasets.MNIST(\"root\", train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "860f6baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only do 0's and 1's\n",
    "#training_data.data = training_data.data[training_data.targets<=1]\n",
    "#training_data.targets = training_data.targets[training_data.targets<=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca0e3aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:\t  torch.Size([60000, 28, 28])\n",
      "Testing data size:\t  torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Display information on datasets\n",
    "print(\"Training data size:\\t \", training_data.data.size())\n",
    "print(\"Testing data size:\\t \", testing_data.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c3f747e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '5')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a sample\n",
    "plt.imshow(training_data.data[0])\n",
    "plt.title('%i' % training_data.targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f43abb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare subset of data and shuffle\n",
    "train_dataloader = DataLoader(training_data, batch_size = 50, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_data, batch_size = 100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc4536d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([50, 1, 28, 28])\n",
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "# Showcase dataloader information\n",
    "for batch, (images, labels) in enumerate(train_dataloader): \n",
    "    print(batch)\n",
    "    print(images.size())\n",
    "    print(images.view(images.shape[0], -1).size())\n",
    "    print(labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5534746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "test = torch.nn.functional.one_hot(training_data.targets)\n",
    "print(test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2b0808",
   "metadata": {},
   "source": [
    "## Network Design and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51bc13b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5313, -0.8780, -0.9896], grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubits = 3\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def qnode_3_amplitudes(inputs, weights):\n",
    "    \n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.Hadamard(wires=1)\n",
    "    qml.Hadamard(wires=2)\n",
    "    \n",
    "    qml.RY(inputs[0], wires=0)\n",
    "    qml.RY(inputs[1], wires=1)\n",
    "    qml.RY(inputs[2], wires=2)\n",
    "    \n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[0, 2])\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    \n",
    "    qml.RY(weights[0], wires=0)\n",
    "    qml.RY(weights[1], wires=1)\n",
    "    qml.RY(weights[2], wires=2)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2))\n",
    "\n",
    "weight_shapes = {\"weights\": 3}\n",
    "qlayer_3_amplitudes = qml.qnn.TorchLayer(qnode_3_amplitudes, weight_shapes)\n",
    "\n",
    "qlayer_3_amplitudes(torch.Tensor([1,3,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc57fce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6441, 0.2423, 0.6347, 0.6513], grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubits = 4\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def qnode_4_amplitudes(inputs, weights):\n",
    "    \n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.Hadamard(wires=1)\n",
    "    qml.Hadamard(wires=2)\n",
    "    qml.Hadamard(wires=3)\n",
    "    \n",
    "    qml.RY(inputs[0], wires=0)\n",
    "    qml.RY(inputs[1], wires=1)\n",
    "    qml.RY(inputs[2], wires=2)\n",
    "    qml.RY(inputs[3], wires=3)\n",
    "    \n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[0, 2])\n",
    "    qml.CNOT(wires=[0, 3])\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    qml.CNOT(wires=[1, 3])\n",
    "    qml.CNOT(wires=[2, 3])\n",
    "    \n",
    "    qml.RY(weights[0], wires=0)\n",
    "    qml.RY(weights[1], wires=1)\n",
    "    qml.RY(weights[2], wires=2)\n",
    "    qml.RY(weights[3], wires=3)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2)), qml.expval(qml.PauliZ(3))\n",
    "\n",
    "weight_shapes = {\"weights\": 4}\n",
    "qlayer_4_amplitudes = qml.qnn.TorchLayer(qnode_4_amplitudes, weight_shapes)\n",
    "\n",
    "qlayer_4_amplitudes(torch.Tensor([1,3,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d084442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4917, -0.1420,  0.0794,  0.0311, -0.7777],\n",
       "       grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubits = 5\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def qnode_5_amplitudes(inputs, weights):\n",
    "    \n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.Hadamard(wires=1)\n",
    "    qml.Hadamard(wires=2)\n",
    "    qml.Hadamard(wires=3)\n",
    "    qml.Hadamard(wires=4)\n",
    "    \n",
    "    qml.RY(inputs[0], wires=0)\n",
    "    qml.RY(inputs[1], wires=1)\n",
    "    qml.RY(inputs[2], wires=2)\n",
    "    qml.RY(inputs[3], wires=3)\n",
    "    qml.RY(inputs[4], wires=4)\n",
    "    \n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[0, 2])\n",
    "    qml.CNOT(wires=[0, 3])\n",
    "    qml.CNOT(wires=[0, 4])\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    qml.CNOT(wires=[1, 3])\n",
    "    qml.CNOT(wires=[1, 4])\n",
    "    qml.CNOT(wires=[2, 3])\n",
    "    qml.CNOT(wires=[2, 4])\n",
    "    qml.CNOT(wires=[3, 4])\n",
    "    \n",
    "    qml.RY(weights[0], wires=0)\n",
    "    qml.RY(weights[1], wires=1)\n",
    "    qml.RY(weights[2], wires=2)\n",
    "    qml.RY(weights[3], wires=3)\n",
    "    qml.RY(weights[4], wires=4)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2)), qml.expval(qml.PauliZ(3)), qml.expval(qml.PauliZ(4))\n",
    "\n",
    "weight_shapes = {\"weights\": 5}\n",
    "qlayer_5_amplitudes = qml.qnn.TorchLayer(qnode_5_amplitudes, weight_shapes)\n",
    "\n",
    "qlayer_5_amplitudes(torch.Tensor([1,3,3,5,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eea76937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "(0, 1, 2)\n",
      "(0, 1, 3)\n",
      "(0, 1, 4)\n",
      "(0, 1, 5)\n",
      "(0, 1, 6)\n",
      "(0, 1, 7)\n",
      "(0, 1, 8)\n",
      "(0, 1, 9)\n",
      "(0, 2, 3)\n",
      "(0, 2, 4)\n",
      "(0, 2, 5)\n",
      "(0, 2, 6)\n",
      "(0, 2, 7)\n",
      "(0, 2, 8)\n",
      "(0, 2, 9)\n",
      "(0, 3, 4)\n",
      "(0, 3, 5)\n",
      "(0, 3, 6)\n",
      "(0, 3, 7)\n",
      "(0, 3, 8)\n",
      "(0, 3, 9)\n",
      "(0, 4, 5)\n",
      "(0, 4, 6)\n",
      "(0, 4, 7)\n",
      "(0, 4, 8)\n",
      "(0, 4, 9)\n",
      "(0, 5, 6)\n",
      "(0, 5, 7)\n",
      "(0, 5, 8)\n",
      "(0, 5, 9)\n",
      "(0, 6, 7)\n",
      "(0, 6, 8)\n",
      "(0, 6, 9)\n",
      "(0, 7, 8)\n",
      "(0, 7, 9)\n",
      "(0, 8, 9)\n",
      "(1, 2, 3)\n",
      "(1, 2, 4)\n",
      "(1, 2, 5)\n",
      "(1, 2, 6)\n",
      "(1, 2, 7)\n",
      "(1, 2, 8)\n",
      "(1, 2, 9)\n",
      "(1, 3, 4)\n",
      "(1, 3, 5)\n",
      "(1, 3, 6)\n",
      "(1, 3, 7)\n",
      "(1, 3, 8)\n",
      "(1, 3, 9)\n",
      "(1, 4, 5)\n",
      "(1, 4, 6)\n",
      "(1, 4, 7)\n",
      "(1, 4, 8)\n",
      "(1, 4, 9)\n",
      "(1, 5, 6)\n",
      "(1, 5, 7)\n",
      "(1, 5, 8)\n",
      "(1, 5, 9)\n",
      "(1, 6, 7)\n",
      "(1, 6, 8)\n",
      "(1, 6, 9)\n",
      "(1, 7, 8)\n",
      "(1, 7, 9)\n",
      "(1, 8, 9)\n",
      "(2, 3, 4)\n",
      "(2, 3, 5)\n",
      "(2, 3, 6)\n",
      "(2, 3, 7)\n",
      "(2, 3, 8)\n",
      "(2, 3, 9)\n",
      "(2, 4, 5)\n",
      "(2, 4, 6)\n",
      "(2, 4, 7)\n",
      "(2, 4, 8)\n",
      "(2, 4, 9)\n",
      "(2, 5, 6)\n",
      "(2, 5, 7)\n",
      "(2, 5, 8)\n",
      "(2, 5, 9)\n",
      "(2, 6, 7)\n",
      "(2, 6, 8)\n",
      "(2, 6, 9)\n",
      "(2, 7, 8)\n",
      "(2, 7, 9)\n",
      "(2, 8, 9)\n",
      "(3, 4, 5)\n",
      "(3, 4, 6)\n",
      "(3, 4, 7)\n",
      "(3, 4, 8)\n",
      "(3, 4, 9)\n",
      "(3, 5, 6)\n",
      "(3, 5, 7)\n",
      "(3, 5, 8)\n",
      "(3, 5, 9)\n",
      "(3, 6, 7)\n",
      "(3, 6, 8)\n",
      "(3, 6, 9)\n",
      "(3, 7, 8)\n",
      "(3, 7, 9)\n",
      "(3, 8, 9)\n",
      "(4, 5, 6)\n",
      "(4, 5, 7)\n",
      "(4, 5, 8)\n",
      "(4, 5, 9)\n",
      "(4, 6, 7)\n",
      "(4, 6, 8)\n",
      "(4, 6, 9)\n",
      "(4, 7, 8)\n",
      "(4, 7, 9)\n",
      "(4, 8, 9)\n",
      "(5, 6, 7)\n",
      "(5, 6, 8)\n",
      "(5, 6, 9)\n",
      "(5, 7, 8)\n",
      "(5, 7, 9)\n",
      "(5, 8, 9)\n",
      "(6, 7, 8)\n",
      "(6, 7, 9)\n",
      "(6, 8, 9)\n",
      "(7, 8, 9)\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "lst = list(range(0,10))\n",
    "print(lst)\n",
    "i=0\n",
    "for combo in combinations( list(range(0,10)), 3): \n",
    "    print(combo)\n",
    "    i +=1\n",
    "    \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8ef4614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network \n",
    "# Great source: https://pennylane.ai/qml/demos/tutorial_qnn_module_torch.html\n",
    "# Note that in_channels = 1 because the input is a grayscale image\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(in_features=784, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=10),\n",
    "        )\n",
    "        \n",
    "        self.final = nn.Sequential(nn.Linear(in_features=360, out_features=64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(in_features=64, out_features=10),\n",
    "                                    nn.LogSoftmax(dim=1))\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.main(x)\n",
    "        x_split = torch.split(x, 1, dim=1)\n",
    "        x_split = list(x_split)\n",
    "\n",
    "        x_out = []\n",
    "        \n",
    "        for combo in combinations(list(range(0,10)), 3):\n",
    "            x_temp = torch.cat([x_split[combo[0]], x_split[combo[1]], x_split[combo[2]]], dim=1)\n",
    "            x_out.append(qlayer_3_amplitudes(x_temp))\n",
    "        \n",
    "        x = torch.cat(x_out, dim=1)\n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0a602f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m test \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m784\u001b[39m)\n\u001b[0;32m      5\u001b[0m test \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2.0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m combo \u001b[38;5;129;01min\u001b[39;00m combinations(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m10\u001b[39m)), \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m     34\u001b[0m     x_temp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x_split[combo[\u001b[38;5;241m0\u001b[39m]], x_split[combo[\u001b[38;5;241m1\u001b[39m]], x_split[combo[\u001b[38;5;241m2\u001b[39m]]], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m     x_out\u001b[38;5;241m.\u001b[39mappend(\u001b[43mqlayer_3_amplitudes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_temp\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(x_out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     38\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal(x)\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\qnn\\torch.py:277\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    275\u001b[0m     reconstructor \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39munbind(inputs):\n\u001b[1;32m--> 277\u001b[0m         reconstructor\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(reconstructor)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# If the input is 1-dimensional, calculate the forward pass as usual\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\qnn\\torch.py:281\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(reconstructor)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# If the input is 1-dimensional, calculate the forward pass as usual\u001b[39;00m\n\u001b[1;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_qnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\qnn\\torch.py:296\u001b[0m, in \u001b[0;36mTorchLayer._evaluate_qnode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m\"\"\"Evaluates the QNode for a single input datapoint.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    tensor: output datapoint\u001b[39;00m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    292\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_arg: x},\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{arg: weight\u001b[38;5;241m.\u001b[39mto(x) \u001b[38;5;28;01mfor\u001b[39;00m arg, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode_weights\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[0;32m    295\u001b[0m }\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mtype(x\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\qnode.py:561\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# preprocess the tapes by applying any device-specific transforms\u001b[39;00m\n\u001b[0;32m    559\u001b[0m tapes, processing_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mbatch_transform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtape)\n\u001b[1;32m--> 561\u001b[0m res \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m    562\u001b[0m     tapes,\n\u001b[0;32m    563\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[0;32m    564\u001b[0m     gradient_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_fn,\n\u001b[0;32m    565\u001b[0m     interface\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterface,\n\u001b[0;32m    566\u001b[0m     gradient_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_kwargs,\n\u001b[0;32m    567\u001b[0m     override_shots\u001b[38;5;241m=\u001b[39moverride_shots,\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute_kwargs,\n\u001b[0;32m    569\u001b[0m )\n\u001b[0;32m    571\u001b[0m res \u001b[38;5;241m=\u001b[39m processing_fn(res)\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m override_shots \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;66;03m# restore the initialization gradient function\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\interfaces\\batch\\__init__.py:321\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(tapes, device, gradient_fn, interface, mode, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion)\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gradient_fn \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackprop\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m interface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcache_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_execute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# the default execution function is batch_execute\u001b[39;00m\n\u001b[0;32m    324\u001b[0m execute_fn \u001b[38;5;241m=\u001b[39m cache_execute(batch_execute, cache, expand_fn\u001b[38;5;241m=\u001b[39mexpand_fn)\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\interfaces\\batch\\__init__.py:168\u001b[0m, in \u001b[0;36mcache_execute.<locals>.wrapper\u001b[1;34m(tapes, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (res, []) \u001b[38;5;28;01mif\u001b[39;00m return_tuple \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# execute all unique tapes that do not exist in the cache\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m     res \u001b[38;5;241m=\u001b[39m fn(execution_tapes\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    170\u001b[0m final_res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tape \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tapes):\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\interfaces\\batch\\__init__.py:120\u001b[0m, in \u001b[0;36mcache_execute.<locals>.fn\u001b[1;34m(tapes, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(tapes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# pylint: disable=function-redefined\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     tapes \u001b[38;5;241m=\u001b[39m [expand_fn(tape) \u001b[38;5;28;01mfor\u001b[39;00m tape \u001b[38;5;129;01min\u001b[39;00m tapes]\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn(tapes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Program Files\\Python39\\lib\\contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\_qubit_device.py:278\u001b[0m, in \u001b[0;36mQubitDevice.batch_execute\u001b[1;34m(self, circuits)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m circuit \u001b[38;5;129;01min\u001b[39;00m circuits:\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;66;03m# we need to reset the device here, else it will\u001b[39;00m\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;66;03m# not start the next computation in the zero state\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m--> 278\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(res)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mactive:\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\devices\\default_qubit_torch.py:232\u001b[0m, in \u001b[0;36mDefaultQubitTorch.execute\u001b[1;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m params_cuda_device \u001b[38;5;241m!=\u001b[39m specified_device_cuda:\n\u001b[0;32m    225\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    226\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch device \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_torch_device\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m specified \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    227\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupon PennyLane device creation does not match the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch device of the gate parameters; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_torch_device\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m             )\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mexecute(circuit, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\_qubit_device.py:194\u001b[0m, in \u001b[0;36mQubitDevice.execute\u001b[1;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_validity(circuit\u001b[38;5;241m.\u001b[39moperations, circuit\u001b[38;5;241m.\u001b[39mobservables)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# apply all circuit operations\u001b[39;00m\n\u001b[1;32m--> 194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(circuit\u001b[38;5;241m.\u001b[39moperations, rotations\u001b[38;5;241m=\u001b[39mcircuit\u001b[38;5;241m.\u001b[39mdiagonalizing_gates, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# generate computational basis samples\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshots \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m circuit\u001b[38;5;241m.\u001b[39mis_sampled:\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\devices\\default_qubit.py:216\u001b[0m, in \u001b[0;36mDefaultQubit.apply\u001b[1;34m(self, operations, rotations, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_basis_state(operation\u001b[38;5;241m.\u001b[39mparameters[\u001b[38;5;241m0\u001b[39m], operation\u001b[38;5;241m.\u001b[39mwires)\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_operation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# store the pre-rotated state\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_rotated_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\devices\\default_qubit.py:239\u001b[0m, in \u001b[0;36mDefaultQubit._apply_operation\u001b[1;34m(self, state, operation)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m operation\u001b[38;5;241m.\u001b[39mbase_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_ops:\n\u001b[0;32m    238\u001b[0m     axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwires\u001b[38;5;241m.\u001b[39mindices(wires)\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_ops\u001b[49m\u001b[43m[\u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_unitary_matrix(operation)\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m operation \u001b[38;5;129;01min\u001b[39;00m diagonal_in_z_basis:\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\devices\\default_qubit.py:358\u001b[0m, in \u001b[0;36mDefaultQubit._apply_cnot\u001b[1;34m(self, state, axes, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     target_axes \u001b[38;5;241m=\u001b[39m [axes[\u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m--> 358\u001b[0m state_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_x\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[43msl_1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_axes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stack([state[sl_0], state_x], axis\u001b[38;5;241m=\u001b[39maxes[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\devices\\default_qubit.py:266\u001b[0m, in \u001b[0;36mDefaultQubit._apply_x\u001b[1;34m(self, state, axes, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply_x\u001b[39m(\u001b[38;5;28mself\u001b[39m, state, axes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;124;03m\"\"\"Applies a PauliX gate by rolling 1 unit along the axis specified in ``axes``.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \n\u001b[0;32m    254\u001b[0m \u001b[38;5;124;03m    Rolling by 1 unit along the axis means that the :math:`|0 \\rangle` state with index ``0`` is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m        array[complex]: output state\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_roll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# View neural network \n",
    "model = Net()\n",
    "test = training_data.data[0:100]\n",
    "test = test.view(-1, 784)\n",
    "test = test/2.0\n",
    "y = model.forward(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c7b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchsummary import summary\n",
    "#summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a80de6",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3e5409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training routine\n",
    "import time\n",
    "\n",
    "def train(epochs):\n",
    "    epoch_list = []\n",
    "    accuracy_list = []\n",
    "    loss_list = []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        accuracy = 0\n",
    "        running_loss = 0\n",
    "\n",
    "        for batch_idx, (image, labels) in enumerate(train_dataloader):\n",
    "            start = time.time()\n",
    "            output = model(image)                           # Find network output\n",
    "            loss = loss_function(output, labels)              # Compute loss\n",
    "\n",
    "            predicted = torch.max(output.data, 1)[1]          # Find predicted value\n",
    "            batch_corr = (predicted == labels).sum()          # Find number of correct values\n",
    "            batch_accuracy = (100*batch_corr / len(labels))    \n",
    "            accuracy+=batch_accuracy/60\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()                             # Clear gradients for this training step\n",
    "            loss.backward()                                   # Compute gradients from backpropagation \n",
    "            optimizer.step()                                  # Apply changes from gradients\n",
    "            end = time.time()\n",
    "            print(\"Batch accuracy: %.2f Time: %.2f\" % (batch_accuracy, (end - start)))\n",
    "\n",
    "        print(\"Training accuracy: %.2f \\t Training loss: %.2f \" % (accuracy, running_loss))\n",
    "        epoch_list.append(epoch)\n",
    "        accuracy_list.append(accuracy)\n",
    "        loss_list.append(running_loss)\n",
    "    return epoch_list, accuracy_list, loss_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc77c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "epochs, accuracy, loss = train(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cf3464",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c48639",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b76ece",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cadf05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(): \n",
    "    accuracy = 0\n",
    "    with torch.no_grad(): \n",
    "        for image, labels in enumerate(test_dataloader): \n",
    "            output = network(image)\n",
    "            predicted = torch.max(output.data, 1)[1]\n",
    "            accuracy += (100*(predicted == labels).sum() / len(labels))\n",
    "    print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde859be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a11a1f8",
   "metadata": {},
   "source": [
    "# Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca0c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b9b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd069e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd58fbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e393f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba912c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = [] \n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 10\n",
    "\n",
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            torch.save(network.state_dict(), '/results/model.pth')\n",
    "            torch.save(optimizer.state_dict(), '/results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e00b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ec097",
   "metadata": {},
   "outputs": [],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2702ff91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
