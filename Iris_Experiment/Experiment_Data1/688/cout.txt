2022-03-10 17:05:27.372654: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64/nvidia:
2022-03-10 17:05:27.372906: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-03-10 17:05:27.373011: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cac060): /proc/driver/nvidia/version does not exist
2022-03-10 17:05:27.374807: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/30
3/8 [==========>...................] - ETA: 19s - loss: 1.8708 - accuracy: 0.4667 - net_norm: 1.0000 00 - val_loss: 0.8361 - val_accuracy: 0.5500 - val_net_norm: 1.0000
Epoch 2/30
1/8 [==>...........................] - ETA: 25s - loss: 1.4774 - accuracy: 0.2000 - net_norm: 1.0000000 - val_loss: 0.4205 - val_accuracy: 0.8500 - val_net_norm: 1.0000
Epoch 3/30
2/8 [======>.......................] - ETA: 24s - loss: 0.4187 - accuracy: 0.7500 - net_norm: 1.0000000 - val_loss: 0.3454 - val_accuracy: 0.9500 - val_net_norm: 1.0000
Epoch 4/30
1/8 [==>...........................] - ETA: 31s - loss: 0.3881 - accuracy: 0.9000 - net_norm: 1.0000000 - val_loss: 0.3405 - val_accuracy: 0.9500 - val_net_norm: 1.0000
Epoch 5/30
2/8 [======>.......................] - ETA: 22s - loss: 0.2926 - accuracy: 1.0000 - net_norm: 1.0000000 - val_loss: 0.3414 - val_accuracy: 0.9500 - val_net_norm: 1.0000
Epoch 6/30
3/8 [==========>...................] - ETA: 20s - loss: 0.2902 - accuracy: 0.9667 - net_norm: 1.0000000 - val_loss: 0.3371 - val_accuracy: 0.9500 - val_net_norm: 1.0000
Epoch 7/30
2/8 [======>.......................] - ETA: 22s - loss: 0.2554 - accuracy: 1.0000 - net_norm: 1.0000000 - val_loss: 0.3282 - val_accuracy: 0.9500 - val_net_norm: 1.0000
Epoch 8/30
1/8 [==>...........................] - ETA: 26s - loss: 0.2912 - accuracy: 0.9000 - net_norm: 1.0000000 - val_loss: 0.3207 - val_accuracy: 0.9000 - val_net_norm: 1.0000
Epoch 9/30
2/8 [======>.......................] - ETA: 20s - loss: 0.2199 - accuracy: 1.0000 - net_norm: 1.0000000 - val_loss: 0.3164 - val_accuracy: 0.9000 - val_net_norm: 1.0000
Epoch 10/30
1/8 [==>...........................] - ETA: 25s - loss: 0.2288 - accuracy: 1.0000 - net_norm: 1.0000000 - val_loss: 0.3128 - val_accuracy: 0.9000 - val_net_norm: 1.0000
Epoch 11/30
2/8 [======>.......................] - ETA: 20s - loss: 0.2101 - accuracy: 1.0000 - net_norm: 1.0000000 - val_loss: 0.3131 - val_accuracy: 0.9000 - val_net_norm: 1.0000
Epoch 12/30
1/8 [==>...........................] - ETA: 27s - loss: 0.2471 - accuracy: 1.0000 - net_norm: 1.0000000 - val_loss: 0.3116 - val_accuracy: 0.9000 - val_net_norm: 1.0000
Epoch 13/30
2/8 [======>.......................] - ETA: 22s - loss: 0.1984 - accuracy: 1.0000 - net_norm: 1.0000000 - val_loss: 0.3118 - val_accuracy: 0.9000 - val_net_norm: 1.0000
Epoch 14/30
1/8 [==>...........................] - ETA: 26s - loss: 0.1826 - accuracy: 1.0000 - net_norm: 1.0000000 - val_loss: 0.3108 - val_accuracy: 0.9000 - val_net_norm: 1.0000
Epoch 15/30
2/8 [======>.......................] - ETA: 22s - loss: 0.2114 - accuracy: 1.0000 - net_norm: 1.0000000 - val_loss: 0.3126 - val_accuracy: 0.9000 - val_net_norm: 1.0000
Epoch 16/30
1/8 [==>...........................] - ETA: 28s - loss: 0.3334 - accuracy: 0.9000 - net_norm: 1.0000000 - val_loss: 0.3105 - val_accuracy: 0.9000 - val_net_norm: 1.0000
Epoch 17/30
2/8 [======>.......................] - ETA: 21s - loss: 0.2411 - accuracy: 1.0000 - net_norm: 1.0000000 - val_loss: 0.3089 - val_accuracy: 0.9000 - val_net_norm: 1.0000
Epoch 18/30
1/8 [==>...........................] - ETA: 27s - loss: 0.2249 - accuracy: 1.0000 - net_norm: 1.0000000 - val_loss: 0.3118 - val_accuracy: 0.8500 - val_net_norm: 1.0000
Epoch 19/30
2/8 [======>.......................] - ETA: 23s - loss: 0.2163 - accuracy: 0.9500 - net_norm: 1.0000000 - val_loss: 0.3123 - val_accuracy: 0.8500 - val_net_norm: 1.0000
Epoch 20/30
3/8 [==========>...................] - ETA: 18s - loss: 0.2497 - accuracy: 0.9333 - net_norm: 1.0000000 - val_loss: 0.3089 - val_accuracy: 0.8500 - val_net_norm: 1.0000
Epoch 21/30
2/8 [======>.......................] - ETA: 23s - loss: 0.1683 - accuracy: 0.9500 - net_norm: 0.9999000 - val_loss: 0.3104 - val_accuracy: 0.8500 - val_net_norm: 1.0000
Epoch 22/30
3/8 [==========>...................] - ETA: 19s - loss: 0.1811 - accuracy: 0.9667 - net_norm: 0.9999999 - val_loss: 0.3061 - val_accuracy: 0.9000 - val_net_norm: 0.9999
Epoch 23/30
2/8 [======>.......................] - ETA: 20s - loss: 0.1738 - accuracy: 1.0000 - net_norm: 0.9999999 - val_loss: 0.3026 - val_accuracy: 0.9000 - val_net_norm: 0.9999
Epoch 24/30
8/8 [==============================] - 34s 4s/step - loss: 0.1715 - accuracy: 0.9625 - net_norm: 0.9999 - val_loss: 0.3115 - val_accuracy: 0.9000 - val_net_norm: 0.9999
Epoch 25/30
1/8 [==>...........................] - ETA: 25s - loss: 0.1069 - accuracy: 1.0000 - net_norm: 0.9999998 - val_loss: 0.3042 - val_accuracy: 0.9000 - val_net_norm: 0.9998
Epoch 26/30
2/8 [======>.......................] - ETA: 25s - loss: 0.1206 - accuracy: 1.0000 - net_norm: 0.9998998 - val_loss: 0.3042 - val_accuracy: 0.9000 - val_net_norm: 0.9998
Epoch 27/30
8/8 [==============================] - 35s 4s/step - loss: 0.1569 - accuracy: 0.9875 - net_norm: 0.9997 - val_loss: 0.3045 - val_accuracy: 0.9000 - val_net_norm: 0.9997
Epoch 28/30
1/8 [==>...........................] - ETA: 26s - loss: 0.1411 - accuracy: 1.0000 - net_norm: 0.9999996 - val_loss: 0.3024 - val_accuracy: 0.9000 - val_net_norm: 0.9995
Epoch 29/30
1/8 [==>...........................] - ETA: 28s - loss: 0.1254 - accuracy: 1.0000 - net_norm: 1.0000