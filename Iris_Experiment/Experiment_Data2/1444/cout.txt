2022-03-11 05:24:39.598957: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64/nvidia:
2022-03-11 05:24:39.599126: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-03-11 05:24:39.599200: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cac057): /proc/driver/nvidia/version does not exist
2022-03-11 05:24:39.601054: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/30
3/8 [==========>...................] - ETA: 13s - loss: 1.1628 - accuracy: 0.4667 - net_norm: 0.5990087 - val_loss: 0.7855 - val_accuracy: 0.4500 - val_net_norm: 0.5906
Epoch 2/30
1/8 [==>...........................] - ETA: 20s - loss: 0.6422 - accuracy: 0.8000 - net_norm: 0.4282698 - val_loss: 0.7212 - val_accuracy: 0.7000 - val_net_norm: 0.5838
Epoch 3/30
2/8 [======>.......................] - ETA: 16s - loss: 0.6803 - accuracy: 0.9000 - net_norm: 0.5498750 - val_loss: 0.6983 - val_accuracy: 0.6500 - val_net_norm: 0.5932
Epoch 4/30
3/8 [==========>...................] - ETA: 13s - loss: 0.6333 - accuracy: 0.7333 - net_norm: 0.5655847 - val_loss: 0.6563 - val_accuracy: 0.9000 - val_net_norm: 0.6025
Epoch 5/30
1/8 [==>...........................] - ETA: 17s - loss: 0.6479 - accuracy: 0.9000 - net_norm: 0.6124985 - val_loss: 0.6294 - val_accuracy: 0.9000 - val_net_norm: 0.6247
Epoch 6/30
3/8 [==========>...................] - ETA: 14s - loss: 0.6236 - accuracy: 0.9333 - net_norm: 0.6819261 - val_loss: 0.5773 - val_accuracy: 0.9000 - val_net_norm: 0.6595
Epoch 7/30
1/8 [==>...........................] - ETA: 20s - loss: 0.5062 - accuracy: 1.0000 - net_norm: 0.6514646 - val_loss: 0.5266 - val_accuracy: 0.9500 - val_net_norm: 0.6975
Epoch 8/30
2/8 [======>.......................] - ETA: 18s - loss: 0.4715 - accuracy: 0.9500 - net_norm: 0.7276053 - val_loss: 0.4666 - val_accuracy: 0.9500 - val_net_norm: 0.7365
Epoch 9/30
3/8 [==========>...................] - ETA: 14s - loss: 0.3841 - accuracy: 1.0000 - net_norm: 0.7255450 - val_loss: 0.4156 - val_accuracy: 0.9500 - val_net_norm: 0.7779
Epoch 10/30
1/8 [==>...........................] - ETA: 18s - loss: 0.3436 - accuracy: 1.0000 - net_norm: 0.7149882 - val_loss: 0.3841 - val_accuracy: 0.9500 - val_net_norm: 0.8188
Epoch 11/30
2/8 [======>.......................] - ETA: 17s - loss: 0.2798 - accuracy: 1.0000 - net_norm: 0.8593239 - val_loss: 0.3610 - val_accuracy: 0.9000 - val_net_norm: 0.8483
Epoch 12/30
3/8 [==========>...................] - ETA: 13s - loss: 0.2695 - accuracy: 0.9667 - net_norm: 0.8585505 - val_loss: 0.3468 - val_accuracy: 0.9000 - val_net_norm: 0.8706
Epoch 13/30
1/8 [==>...........................] - ETA: 19s - loss: 0.2245 - accuracy: 1.0000 - net_norm: 0.8430723 - val_loss: 0.3410 - val_accuracy: 0.9000 - val_net_norm: 0.8877
Epoch 14/30
3/8 [==========>...................] - ETA: 14s - loss: 0.2796 - accuracy: 0.9667 - net_norm: 0.8883855 - val_loss: 0.3310 - val_accuracy: 0.9000 - val_net_norm: 0.8967
Epoch 15/30
1/8 [==>...........................] - ETA: 19s - loss: 0.2393 - accuracy: 1.0000 - net_norm: 0.9668978 - val_loss: 0.3249 - val_accuracy: 0.9000 - val_net_norm: 0.9098
Epoch 16/30
2/8 [======>.......................] - ETA: 15s - loss: 0.2824 - accuracy: 0.9500 - net_norm: 0.9111060 - val_loss: 0.3080 - val_accuracy: 0.9000 - val_net_norm: 0.9157
Epoch 17/30
4/8 [==============>...............] - ETA: 11s - loss: 0.1916 - accuracy: 1.0000 - net_norm: 0.9029133 - val_loss: 0.3087 - val_accuracy: 0.9000 - val_net_norm: 0.9232
Epoch 18/30
1/8 [==>...........................] - ETA: 19s - loss: 0.2114 - accuracy: 1.0000 - net_norm: 0.9386196 - val_loss: 0.3137 - val_accuracy: 0.9000 - val_net_norm: 0.9264
Epoch 19/30
3/8 [==========>...................] - ETA: 13s - loss: 0.2196 - accuracy: 0.9667 - net_norm: 0.9105228 - val_loss: 0.3120 - val_accuracy: 0.8500 - val_net_norm: 0.9309
Epoch 20/30
1/8 [==>...........................] - ETA: 20s - loss: 0.2807 - accuracy: 0.9000 - net_norm: 0.8650284 - val_loss: 0.3005 - val_accuracy: 0.9000 - val_net_norm: 0.9373
Epoch 21/30
6/8 [=====================>........] - ETA: 5s - loss: 0.1844 - accuracy: 0.9833 - net_norm: 0.9376 362 - val_loss: 0.2921 - val_accuracy: 0.9000 - val_net_norm: 0.9432
Epoch 22/30
3/8 [==========>...................] - ETA: 13s - loss: 0.1635 - accuracy: 1.0000 - net_norm: 0.9525415 - val_loss: 0.2772 - val_accuracy: 0.9000 - val_net_norm: 0.9461
Epoch 23/30
5/8 [=================>............] - ETA: 8s - loss: 0.1795 - accuracy: 0.9800 - net_norm: 0.9495 437 - val_loss: 0.2759 - val_accuracy: 0.9000 - val_net_norm: 0.9496
Epoch 24/30
2/8 [======>.......................] - ETA: 15s - loss: 0.2148 - accuracy: 0.9500 - net_norm: 0.9362501 - val_loss: 0.2990 - val_accuracy: 0.9000 - val_net_norm: 0.9555
Epoch 25/30
8/8 [==============================] - ETA: 0s - loss: 0.1629 - accuracy: 0.9875 - net_norm: 0.9553 553 - val_loss: 0.2754 - val_accuracy: 0.9000 - val_net_norm: 0.9575
Epoch 26/30
3/8 [==========>...................] - ETA: 13s - loss: 0.1281 - accuracy: 1.0000 - net_norm: 0.9501562 - val_loss: 0.2602 - val_accuracy: 0.9000 - val_net_norm: 0.9584
Epoch 27/30
3/8 [==========>...................] - ETA: 13s - loss: 0.1810 - accuracy: 0.9667 - net_norm: 0.9708577 - val_loss: 0.2655 - val_accuracy: 0.9000 - val_net_norm: 0.9612
Epoch 28/30
5/8 [=================>............] - ETA: 8s - loss: 0.1695 - accuracy: 0.9800 - net_norm: 0.9739 629 - val_loss: 0.2684 - val_accuracy: 0.9000 - val_net_norm: 0.9653
Epoch 29/30
8/8 [==============================] - 26s 3s/step - loss: 0.1462 - accuracy: 0.9875 - net_norm: 0.9662 - val_loss: 0.2599 - val_accuracy: 0.9000 - val_net_norm: 0.9673
