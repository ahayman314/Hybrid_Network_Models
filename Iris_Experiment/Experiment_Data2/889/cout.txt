2022-03-11 03:10:39.528817: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64/nvidia:
2022-03-11 03:10:39.528926: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-03-11 03:10:39.529033: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cac058): /proc/driver/nvidia/version does not exist
2022-03-11 03:10:39.530183: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/30
2/8 [======>.......................] - ETA: 15s - loss: 0.6433 - accuracy: 0.4500 - net_norm: 0.0523707 - val_loss: 0.5636 - val_accuracy: 0.5000 - val_net_norm: 0.0781
Epoch 2/30
4/8 [==============>...............] - ETA: 10s - loss: 0.5838 - accuracy: 0.4500 - net_norm: 0.0756862 - val_loss: 0.5412 - val_accuracy: 0.5000 - val_net_norm: 0.0940
Epoch 3/30
2/8 [======>.......................] - ETA: 16s - loss: 0.5253 - accuracy: 0.5000 - net_norm: 0.0870020 - val_loss: 0.5305 - val_accuracy: 0.5000 - val_net_norm: 0.1121
Epoch 4/30
1/8 [==>...........................] - ETA: 18s - loss: 0.5138 - accuracy: 0.6000 - net_norm: 0.1323189 - val_loss: 0.5187 - val_accuracy: 0.5000 - val_net_norm: 0.1346
Epoch 5/30
2/8 [======>.......................] - ETA: 15s - loss: 0.4884 - accuracy: 0.5000 - net_norm: 0.1243408 - val_loss: 0.5156 - val_accuracy: 0.5000 - val_net_norm: 0.1570
Epoch 6/30
5/8 [=================>............] - ETA: 8s - loss: 0.4911 - accuracy: 0.4800 - net_norm: 0.1467 588 - val_loss: 0.5117 - val_accuracy: 0.5000 - val_net_norm: 0.1776
Epoch 7/30
8/8 [==============================] - 25s 3s/step - loss: 0.4699 - accuracy: 0.5000 - net_norm: 0.1777 - val_loss: 0.5130 - val_accuracy: 0.5000 - val_net_norm: 0.2014
Epoch 8/30
8/8 [==============================] - 24s 3s/step - loss: 0.4589 - accuracy: 0.5000 - net_norm: 0.1974 - val_loss: 0.5084 - val_accuracy: 0.5000 - val_net_norm: 0.2248
Epoch 9/30
6/8 [=====================>........] - ETA: 4s - loss: 0.4714 - accuracy: 0.4667 - net_norm: 0.2037 183 - val_loss: 0.5024 - val_accuracy: 0.5000 - val_net_norm: 0.2462
Epoch 10/30
5/8 [=================>............] - ETA: 7s - loss: 0.4419 - accuracy: 0.5000 - net_norm: 0.2332 350 - val_loss: 0.5134 - val_accuracy: 0.5500 - val_net_norm: 0.2600
Epoch 11/30
7/8 [=========================>....] - ETA: 2s - loss: 0.4072 - accuracy: 0.5000 - net_norm: 0.2366 448 - val_loss: 0.5134 - val_accuracy: 0.5000 - val_net_norm: 0.2712
Epoch 12/30
2/8 [======>.......................] - ETA: 15s - loss: 0.3986 - accuracy: 0.5500 - net_norm: 0.2645548 - val_loss: 0.5252 - val_accuracy: 0.5500 - val_net_norm: 0.2833
Epoch 13/30
3/8 [==========>...................] - ETA: 13s - loss: 0.3621 - accuracy: 0.6333 - net_norm: 0.2838643 - val_loss: 0.5319 - val_accuracy: 0.5500 - val_net_norm: 0.2941
Epoch 14/30
4/8 [==============>...............] - ETA: 10s - loss: 0.4698 - accuracy: 0.5250 - net_norm: 0.2538716 - val_loss: 0.5220 - val_accuracy: 0.6500 - val_net_norm: 0.3024
Epoch 15/30
7/8 [=========================>....] - ETA: 2s - loss: 0.4012 - accuracy: 0.5429 - net_norm: 0.2954 802 - val_loss: 0.5327 - val_accuracy: 0.5000 - val_net_norm: 0.3113
Epoch 16/30
1/8 [==>...........................] - ETA: 19s - loss: 0.5911 - accuracy: 0.4000 - net_norm: 0.2665839 - val_loss: 0.5097 - val_accuracy: 0.6500 - val_net_norm: 0.3163
Epoch 17/30
5/8 [=================>............] - ETA: 7s - loss: 0.3975 - accuracy: 0.6400 - net_norm: 0.2943 964 - val_loss: 0.5315 - val_accuracy: 0.5500 - val_net_norm: 0.3398
Epoch 18/30
5/8 [=================>............] - ETA: 8s - loss: 0.4158 - accuracy: 0.5600 - net_norm: 0.3012 140 - val_loss: 0.5245 - val_accuracy: 0.6000 - val_net_norm: 0.3574
Epoch 19/30
2/8 [======>.......................] - ETA: 15s - loss: 0.5123 - accuracy: 0.8000 - net_norm: 0.2199323 - val_loss: 0.5009 - val_accuracy: 0.8000 - val_net_norm: 0.3783
Epoch 20/30
2/8 [======>.......................] - ETA: 16s - loss: 0.4700 - accuracy: 0.7500 - net_norm: 0.3149596 - val_loss: 0.4961 - val_accuracy: 0.8500 - val_net_norm: 0.4132
Epoch 21/30
3/8 [==========>...................] - ETA: 14s - loss: 0.3582 - accuracy: 0.9000 - net_norm: 0.4162039 - val_loss: 0.4452 - val_accuracy: 0.8500 - val_net_norm: 0.4488
Epoch 22/30
2/8 [======>.......................] - ETA: 16s - loss: 0.2547 - accuracy: 1.0000 - net_norm: 0.5044547 - val_loss: 0.3874 - val_accuracy: 0.8500 - val_net_norm: 0.5109
Epoch 23/30
4/8 [==============>...............] - ETA: 10s - loss: 0.2878 - accuracy: 1.0000 - net_norm: 0.4748299 - val_loss: 0.3353 - val_accuracy: 0.8500 - val_net_norm: 0.5903
Epoch 24/30
2/8 [======>.......................] - ETA: 15s - loss: 0.2585 - accuracy: 1.0000 - net_norm: 0.5494136 - val_loss: 0.2743 - val_accuracy: 0.9000 - val_net_norm: 0.6635
Epoch 25/30
8/8 [==============================] - 24s 3s/step - loss: 0.1482 - accuracy: 0.9750 - net_norm: 0.6956 - val_loss: 0.2209 - val_accuracy: 0.9500 - val_net_norm: 0.7344
Epoch 26/30
8/8 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9875 - net_norm: 0.7688 688 - val_loss: 0.1806 - val_accuracy: 0.9500 - val_net_norm: 0.7754
Epoch 27/30
8/8 [==============================] - 24s 3s/step - loss: 0.0933 - accuracy: 1.0000 - net_norm: 0.7957 - val_loss: 0.1618 - val_accuracy: 0.9500 - val_net_norm: 0.7953
Epoch 28/30
8/8 [==============================] - 25s 3s/step - loss: 0.0765 - accuracy: 1.0000 - net_norm: 0.8404 - val_loss: 0.1492 - val_accuracy: 0.9500 - val_net_norm: 0.8292
Epoch 29/30
6/8 [=====================>........] - ETA: 5s - loss: 0.0778 - accuracy: 1.0000 - net_norm: 0.8546 689 - val_loss: 0.1406 - val_accuracy: 0.9500 - val_net_norm: 0.8422
