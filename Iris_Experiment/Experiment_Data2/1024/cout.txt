2022-03-11 03:46:16.025206: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64/nvidia:
2022-03-11 03:46:16.025395: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-03-11 03:46:16.025515: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cac066): /proc/driver/nvidia/version does not exist
2022-03-11 03:46:16.027120: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/30
3/8 [==========>...................] - ETA: 12s - loss: 0.8927 - accuracy: 0.5333 - net_norm: 1.2341e-06-06 - val_loss: 0.8899 - val_accuracy: 0.5000 - val_net_norm: 1.9602e-06
Epoch 2/30
1/8 [==>...........................] - ETA: 19s - loss: 0.8900 - accuracy: 0.2000 - net_norm: 1.7628e-06-06 - val_loss: 0.8867 - val_accuracy: 0.5000 - val_net_norm: 4.9702e-06
Epoch 3/30
3/8 [==========>...................] - ETA: 13s - loss: 0.8863 - accuracy: 0.5000 - net_norm: 5.9795e-06-05 - val_loss: 0.8835 - val_accuracy: 0.5000 - val_net_norm: 3.1679e-05
Epoch 4/30
1/8 [==>...........................] - ETA: 17s - loss: 0.8835 - accuracy: 0.6000 - net_norm: 3.3435e-05-05 - val_loss: 0.8803 - val_accuracy: 0.5000 - val_net_norm: 1.9066e-04
Epoch 5/30
3/8 [==========>...................] - ETA: 12s - loss: 0.8799 - accuracy: 0.4667 - net_norm: 2.0841e-04-04 - val_loss: 0.8770 - val_accuracy: 0.5000 - val_net_norm: 4.1961e-04
Epoch 6/30
1/8 [==>...........................] - ETA: 17s - loss: 0.8770 - accuracy: 0.5000 - net_norm: 4.2941e-04-04 - val_loss: 0.8737 - val_accuracy: 0.5000 - val_net_norm: 6.4336e-04
Epoch 7/30
3/8 [==========>...................] - ETA: 13s - loss: 0.8733 - accuracy: 0.4667 - net_norm: 6.5301e-04-04 - val_loss: 0.8703 - val_accuracy: 0.5000 - val_net_norm: 9.3564e-04
Epoch 8/30
1/8 [==>...........................] - ETA: 19s - loss: 0.8698 - accuracy: 0.6000 - net_norm: 9.3886e-04- val_loss: 0.8670 - val_accuracy: 0.5000 - val_net_norm: 0.0013
Epoch 9/30
3/8 [==========>...................] - ETA: 13s - loss: 0.8664 - accuracy: 0.5000 - net_norm: 0.0013015 - val_loss: 0.8636 - val_accuracy: 0.5000 - val_net_norm: 0.0018
Epoch 10/30
2/8 [======>.......................] - ETA: 16s - loss: 0.8637 - accuracy: 0.4500 - net_norm: 0.0018020 - val_loss: 0.8601 - val_accuracy: 0.5000 - val_net_norm: 0.0024
Epoch 11/30
4/8 [==============>...............] - ETA: 10s - loss: 0.8596 - accuracy: 0.4750 - net_norm: 0.0024026 - val_loss: 0.8566 - val_accuracy: 0.5000 - val_net_norm: 0.0031
Epoch 12/30
2/8 [======>.......................] - ETA: 15s - loss: 0.8553 - accuracy: 0.5500 - net_norm: 0.0030033 - val_loss: 0.8530 - val_accuracy: 0.5000 - val_net_norm: 0.0039
Epoch 13/30
4/8 [==============>...............] - ETA: 10s - loss: 0.8528 - accuracy: 0.4500 - net_norm: 0.0037041 - val_loss: 0.8495 - val_accuracy: 0.5000 - val_net_norm: 0.0047
Epoch 14/30
2/8 [======>.......................] - ETA: 15s - loss: 0.8470 - accuracy: 0.6000 - net_norm: 0.0049049 - val_loss: 0.8459 - val_accuracy: 0.5000 - val_net_norm: 0.0058
Epoch 15/30
1/8 [==>...........................] - ETA: 20s - loss: 0.8406 - accuracy: 0.7000 - net_norm: 0.0061061 - val_loss: 0.8425 - val_accuracy: 0.5000 - val_net_norm: 0.0072
Epoch 16/30
7/8 [=========================>....] - ETA: 2s - loss: 0.8418 - accuracy: 0.4571 - net_norm: 0.0074 077 - val_loss: 0.8383 - val_accuracy: 0.5000 - val_net_norm: 0.0091
Epoch 17/30
2/8 [======>.......................] - ETA: 16s - loss: 0.8361 - accuracy: 0.5500 - net_norm: 0.0094096 - val_loss: 0.8341 - val_accuracy: 0.5000 - val_net_norm: 0.0111
Epoch 18/30
3/8 [==========>...................] - ETA: 13s - loss: 0.8386 - accuracy: 0.3667 - net_norm: 0.0101117 - val_loss: 0.8298 - val_accuracy: 0.5000 - val_net_norm: 0.0137
Epoch 19/30
1/8 [==>...........................] - ETA: 19s - loss: 0.8471 - accuracy: 0.2000 - net_norm: 0.0117145 - val_loss: 0.8253 - val_accuracy: 0.5000 - val_net_norm: 0.0171
Epoch 20/30
2/8 [======>.......................] - ETA: 15s - loss: 0.8310 - accuracy: 0.4000 - net_norm: 0.0160182 - val_loss: 0.8205 - val_accuracy: 0.5000 - val_net_norm: 0.0216
Epoch 21/30
1/8 [==>...........................] - ETA: 19s - loss: 0.8275 - accuracy: 0.4000 - net_norm: 0.0197230 - val_loss: 0.8153 - val_accuracy: 0.5000 - val_net_norm: 0.0275
Epoch 22/30
1/8 [==>...........................] - ETA: 20s - loss: 0.7987 - accuracy: 0.6000 - net_norm: 0.0265295 - val_loss: 0.8104 - val_accuracy: 0.5000 - val_net_norm: 0.0350
Epoch 23/30
8/8 [==============================] - 24s 3s/step - loss: 0.8065 - accuracy: 0.5000 - net_norm: 0.0364 - val_loss: 0.8060 - val_accuracy: 0.5000 - val_net_norm: 0.0423
Epoch 24/30
4/8 [==============>...............] - ETA: 10s - loss: 0.7991 - accuracy: 0.5250 - net_norm: 0.0434441 - val_loss: 0.8011 - val_accuracy: 0.5000 - val_net_norm: 0.0515
Epoch 25/30
6/8 [=====================>........] - ETA: 5s - loss: 0.7953 - accuracy: 0.5000 - net_norm: 0.0521 527 - val_loss: 0.7965 - val_accuracy: 0.5000 - val_net_norm: 0.0597
Epoch 26/30
8/8 [==============================] - ETA: 0s - loss: 0.7883 - accuracy: 0.5000 - net_norm: 0.0614 614 - val_loss: 0.7925 - val_accuracy: 0.5000 - val_net_norm: 0.0696
Epoch 27/30
3/8 [==========>...................] - ETA: 11s - loss: 0.7936 - accuracy: 0.5000 - net_norm: 0.0712699 - val_loss: 0.7888 - val_accuracy: 0.5000 - val_net_norm: 0.0782
Epoch 28/30
1/8 [==>...........................] - ETA: 19s - loss: 0.7851 - accuracy: 0.5000 - net_norm: 0.0768786 - val_loss: 0.7868 - val_accuracy: 0.5000 - val_net_norm: 0.0887
Epoch 29/30
2/8 [======>.......................] - ETA: 15s - loss: 0.7289 - accuracy: 0.6000 - net_norm: 0.0890