2022-03-11 03:45:59.909465: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64/nvidia:
2022-03-11 03:45:59.909709: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-03-11 03:45:59.909868: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cac056): /proc/driver/nvidia/version does not exist
2022-03-11 03:45:59.911751: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/30
4/8 [==============>...............] - ETA: 10s - loss: 1.5627 - accuracy: 0.4500 - net_norm: 0.8734663 - val_loss: 0.8079 - val_accuracy: 0.5000 - val_net_norm: 0.8347
Epoch 2/30
2/8 [======>.......................] - ETA: 17s - loss: 0.8203 - accuracy: 0.2000 - net_norm: 0.8168130 - val_loss: 0.8201 - val_accuracy: 0.5000 - val_net_norm: 0.7993
Epoch 3/30
4/8 [==============>...............] - ETA: 10s - loss: 0.8317 - accuracy: 0.4500 - net_norm: 0.8054008 - val_loss: 0.7726 - val_accuracy: 0.5000 - val_net_norm: 0.8055
Epoch 4/30
2/8 [======>.......................] - ETA: 16s - loss: 0.7464 - accuracy: 0.5000 - net_norm: 0.8019152 - val_loss: 0.7073 - val_accuracy: 0.5000 - val_net_norm: 0.8236
Epoch 5/30
4/8 [==============>...............] - ETA: 9s - loss: 0.6928 - accuracy: 0.5250 - net_norm: 0.8340 344 - val_loss: 0.6818 - val_accuracy: 0.7500 - val_net_norm: 0.8396
Epoch 6/30
3/8 [==========>...................] - ETA: 12s - loss: 0.6965 - accuracy: 0.7667 - net_norm: 0.8647504 - val_loss: 0.6647 - val_accuracy: 0.8000 - val_net_norm: 0.8530
Epoch 7/30
2/8 [======>.......................] - ETA: 13s - loss: 0.6265 - accuracy: 0.9500 - net_norm: 0.8514639 - val_loss: 0.6452 - val_accuracy: 0.9000 - val_net_norm: 0.8687
Epoch 8/30
4/8 [==============>...............] - ETA: 10s - loss: 0.6376 - accuracy: 0.9250 - net_norm: 0.8818794 - val_loss: 0.6268 - val_accuracy: 0.9000 - val_net_norm: 0.8834
Epoch 9/30
2/8 [======>.......................] - ETA: 15s - loss: 0.5982 - accuracy: 1.0000 - net_norm: 0.8910920 - val_loss: 0.6068 - val_accuracy: 0.9000 - val_net_norm: 0.8955
Epoch 10/30
1/8 [==>...........................] - ETA: 18s - loss: 0.6054 - accuracy: 1.0000 - net_norm: 0.8956032 - val_loss: 0.5854 - val_accuracy: 0.9000 - val_net_norm: 0.9078
Epoch 11/30
3/8 [==========>...................] - ETA: 13s - loss: 0.5441 - accuracy: 0.9667 - net_norm: 0.9168154 - val_loss: 0.5666 - val_accuracy: 0.9500 - val_net_norm: 0.9199
Epoch 12/30
2/8 [======>.......................] - ETA: 15s - loss: 0.5291 - accuracy: 0.9500 - net_norm: 0.9244253 - val_loss: 0.5496 - val_accuracy: 0.9500 - val_net_norm: 0.9290
Epoch 13/30
4/8 [==============>...............] - ETA: 10s - loss: 0.4897 - accuracy: 1.0000 - net_norm: 0.9274339 - val_loss: 0.5365 - val_accuracy: 0.9000 - val_net_norm: 0.9367
Epoch 14/30
2/8 [======>.......................] - ETA: 16s - loss: 0.5228 - accuracy: 0.9000 - net_norm: 0.9479402 - val_loss: 0.5248 - val_accuracy: 0.9000 - val_net_norm: 0.9424
Epoch 15/30
1/8 [==>...........................] - ETA: 19s - loss: 0.5118 - accuracy: 1.0000 - net_norm: 0.9633470 - val_loss: 0.5183 - val_accuracy: 0.8500 - val_net_norm: 0.9497
Epoch 16/30
3/8 [==========>...................] - ETA: 13s - loss: 0.4776 - accuracy: 0.9333 - net_norm: 0.9507523 - val_loss: 0.5037 - val_accuracy: 0.8500 - val_net_norm: 0.9539
Epoch 17/30
4/8 [==============>...............] - ETA: 9s - loss: 0.4508 - accuracy: 0.9500 - net_norm: 0.9537 571 - val_loss: 0.4960 - val_accuracy: 0.8500 - val_net_norm: 0.9592
Epoch 18/30
7/8 [=========================>....] - ETA: 2s - loss: 0.4390 - accuracy: 0.9714 - net_norm: 0.9638 618 - val_loss: 0.4848 - val_accuracy: 0.8500 - val_net_norm: 0.9631
Epoch 19/30
3/8 [==========>...................] - ETA: 11s - loss: 0.4366 - accuracy: 0.9667 - net_norm: 0.9615653 - val_loss: 0.4751 - val_accuracy: 0.8500 - val_net_norm: 0.9667
Epoch 20/30
1/8 [==>...........................] - ETA: 19s - loss: 0.4159 - accuracy: 0.9000 - net_norm: 0.9547689 - val_loss: 0.4665 - val_accuracy: 0.8500 - val_net_norm: 0.9701
Epoch 21/30
1/8 [==>...........................] - ETA: 17s - loss: 0.4017 - accuracy: 0.9000 - net_norm: 0.9585724 - val_loss: 0.4607 - val_accuracy: 0.8500 - val_net_norm: 0.9734
Epoch 22/30
2/8 [======>.......................] - ETA: 15s - loss: 0.3690 - accuracy: 1.0000 - net_norm: 0.9776751 - val_loss: 0.4506 - val_accuracy: 0.9000 - val_net_norm: 0.9753
Epoch 23/30
1/8 [==>...........................] - ETA: 18s - loss: 0.3881 - accuracy: 1.0000 - net_norm: 0.9707760 - val_loss: 0.4452 - val_accuracy: 0.9000 - val_net_norm: 0.9769
Epoch 24/30
8/8 [==============================] - 24s 3s/step - loss: 0.3809 - accuracy: 0.9625 - net_norm: 0.9791 - val_loss: 0.4641 - val_accuracy: 0.8500 - val_net_norm: 0.9801
Epoch 25/30
7/8 [=========================>....] - ETA: 2s - loss: 0.3675 - accuracy: 0.9429 - net_norm: 0.9805 805 - val_loss: 0.4367 - val_accuracy: 0.9000 - val_net_norm: 0.9800
Epoch 26/30
8/8 [==============================] - ETA: 0s - loss: 0.3709 - accuracy: 0.9875 - net_norm: 0.9813 813 - val_loss: 0.4320 - val_accuracy: 0.9000 - val_net_norm: 0.9823
Epoch 27/30
8/8 [==============================] - 24s 3s/step - loss: 0.3616 - accuracy: 0.9750 - net_norm: 0.9831 - val_loss: 0.4321 - val_accuracy: 0.8500 - val_net_norm: 0.9839
Epoch 28/30
3/8 [==========>...................] - ETA: 12s - loss: 0.3586 - accuracy: 0.9333 - net_norm: 0.9875846 - val_loss: 0.4243 - val_accuracy: 0.9000 - val_net_norm: 0.9847
Epoch 29/30
8/8 [==============================] - ETA: 0s - loss: 0.3527 - accuracy: 0.9500 - net_norm: 0.9854 854 - val_loss: 0.4186 - val_accuracy: 0.9000 - val_net_norm: 0.9854
