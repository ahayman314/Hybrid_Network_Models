2022-03-11 01:12:29.355727: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64/nvidia:
2022-03-11 01:12:29.355881: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-03-11 01:12:29.356000: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cac029): /proc/driver/nvidia/version does not exist
2022-03-11 01:12:29.358273: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/30
1/8 [==>...........................] - ETA: 1:07 - loss: 0.6931 - accuracy: 0.4000 - net_norm: 6.7938e-0807 - val_loss: 0.6931 - val_accuracy: 0.5000 - val_net_norm: 1.5051e-07
Epoch 2/30
8/8 [==============================] - 23s 3s/step - loss: 0.6931 - accuracy: 0.5000 - net_norm: 3.7532e-07 - val_loss: 0.6931 - val_accuracy: 0.5000 - val_net_norm: 1.0440e-06
Epoch 3/30
8/8 [==============================] - 23s 3s/step - loss: 0.6931 - accuracy: 0.5000 - net_norm: 3.3984e-06 - val_loss: 0.6931 - val_accuracy: 0.5000 - val_net_norm: 9.1146e-06
Epoch 4/30
8/8 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5000 - net_norm: 2.1945e-05 -05 - val_loss: 0.6930 - val_accuracy: 0.5000 - val_net_norm: 4.9940e-05
Epoch 5/30
4/8 [==============>...............] - ETA: 10s - loss: 0.6930 - accuracy: 0.4750 - net_norm: 6.2581e-05-05 - val_loss: 0.6927 - val_accuracy: 0.5000 - val_net_norm: 1.6283e-04
Epoch 6/30
8/8 [==============================] - 22s 3s/step - loss: 0.6926 - accuracy: 0.5000 - net_norm: 2.4994e-04 - val_loss: 0.6923 - val_accuracy: 0.5000 - val_net_norm: 3.5352e-04
Epoch 7/30
3/8 [==========>...................] - ETA: 11s - loss: 0.6923 - accuracy: 0.4667 - net_norm: 3.7050e-04-04 - val_loss: 0.6917 - val_accuracy: 0.5000 - val_net_norm: 6.0991e-04
Epoch 8/30
2/8 [======>.......................] - ETA: 14s - loss: 0.6914 - accuracy: 0.6000 - net_norm: 7.6051e-04-04 - val_loss: 0.6910 - val_accuracy: 0.5000 - val_net_norm: 0.0011
Epoch 9/30
4/8 [==============>...............] - ETA: 8s - loss: 0.6908 - accuracy: 0.5000 - net_norm: 0.0011 012 - val_loss: 0.6901 - val_accuracy: 0.5000 - val_net_norm: 0.0016
Epoch 10/30
7/8 [=========================>....] - ETA: 2s - loss: 0.6893 - accuracy: 0.4857 - net_norm: 0.0018 019 - val_loss: 0.6888 - val_accuracy: 0.5000 - val_net_norm: 0.0025
Epoch 11/30
1/8 [==>...........................] - ETA: 15s - loss: 0.6879 - accuracy: 0.5000 - net_norm: 0.0024028 - val_loss: 0.6869 - val_accuracy: 0.5000 - val_net_norm: 0.0039
Epoch 12/30
1/8 [==>...........................] - ETA: 19s - loss: 0.6869 - accuracy: 0.5000 - net_norm: 0.0031042 - val_loss: 0.6844 - val_accuracy: 0.5000 - val_net_norm: 0.0058
Epoch 13/30
8/8 [==============================] - 23s 3s/step - loss: 0.6809 - accuracy: 0.5000 - net_norm: 0.0061 - val_loss: 0.6806 - val_accuracy: 0.5000 - val_net_norm: 0.0081
Epoch 14/30
8/8 [==============================] - 22s 3s/step - loss: 0.6758 - accuracy: 0.5000 - net_norm: 0.0086 - val_loss: 0.6754 - val_accuracy: 0.5000 - val_net_norm: 0.0114
Epoch 15/30
8/8 [==============================] - 23s 3s/step - loss: 0.6696 - accuracy: 0.5000 - net_norm: 0.0117 - val_loss: 0.6692 - val_accuracy: 0.5000 - val_net_norm: 0.0160
Epoch 16/30
8/8 [==============================] - 22s 3s/step - loss: 0.6600 - accuracy: 0.5000 - net_norm: 0.0166 - val_loss: 0.6598 - val_accuracy: 0.5000 - val_net_norm: 0.0221
Epoch 17/30
8/8 [==============================] - 21s 3s/step - loss: 0.6480 - accuracy: 0.5000 - net_norm: 0.0230 - val_loss: 0.6472 - val_accuracy: 0.5000 - val_net_norm: 0.0308
Epoch 18/30
6/8 [=====================>........] - ETA: 4s - loss: 0.6330 - accuracy: 0.5000 - net_norm: 0.0305 324 - val_loss: 0.6283 - val_accuracy: 0.5000 - val_net_norm: 0.0419
Epoch 19/30
8/8 [==============================] - 23s 3s/step - loss: 0.6086 - accuracy: 0.5000 - net_norm: 0.0462 - val_loss: 0.6058 - val_accuracy: 0.5000 - val_net_norm: 0.0574
Epoch 20/30
1/8 [==>...........................] - ETA: 16s - loss: 0.6303 - accuracy: 0.3000 - net_norm: 0.0356627 - val_loss: 0.5767 - val_accuracy: 0.5000 - val_net_norm: 0.0787
Epoch 21/30
8/8 [==============================] - 22s 3s/step - loss: 0.5520 - accuracy: 0.5000 - net_norm: 0.0854 - val_loss: 0.5423 - val_accuracy: 0.5000 - val_net_norm: 0.1071
Epoch 22/30
8/8 [==============================] - 22s 3s/step - loss: 0.5178 - accuracy: 0.5000 - net_norm: 0.1139 - val_loss: 0.5087 - val_accuracy: 0.5000 - val_net_norm: 0.1406
Epoch 23/30
8/8 [==============================] - 23s 3s/step - loss: 0.4794 - accuracy: 0.5000 - net_norm: 0.1513 - val_loss: 0.4716 - val_accuracy: 0.5000 - val_net_norm: 0.1835
Epoch 24/30
5/8 [=================>............] - ETA: 7s - loss: 0.4400 - accuracy: 0.5400 - net_norm: 0.2051 948 - val_loss: 0.4315 - val_accuracy: 0.5000 - val_net_norm: 0.2253
Epoch 25/30
6/8 [=====================>........] - ETA: 4s - loss: 0.4241 - accuracy: 0.5000 - net_norm: 0.2341 409 - val_loss: 0.4015 - val_accuracy: 0.5000 - val_net_norm: 0.2659
Epoch 26/30
8/8 [==============================] - 21s 3s/step - loss: 0.3888 - accuracy: 0.5000 - net_norm: 0.2745 - val_loss: 0.3773 - val_accuracy: 0.5000 - val_net_norm: 0.3048
Epoch 27/30
8/8 [==============================] - 23s 3s/step - loss: 0.3699 - accuracy: 0.5000 - net_norm: 0.3068 - val_loss: 0.3699 - val_accuracy: 0.5000 - val_net_norm: 0.3350
Epoch 28/30
8/8 [==============================] - ETA: 0s - loss: 0.3702 - accuracy: 0.5000 - net_norm: 0.3287 287 - val_loss: 0.3650 - val_accuracy: 0.5000 - val_net_norm: 0.3398
Epoch 29/30
3/8 [==========>...................] - ETA: 11s - loss: 0.2762 - accuracy: 0.6333 - net_norm: 0.4212