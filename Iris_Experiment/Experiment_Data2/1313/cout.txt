2022-03-11 04:56:17.870208: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64/nvidia:
2022-03-11 04:56:17.870381: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-03-11 04:56:17.870464: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cac032): /proc/driver/nvidia/version does not exist
2022-03-11 04:56:17.872228: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/30
1/8 [==>...........................] - ETA: 1:13 - loss: 0.6931 - accuracy: 0.6000 - net_norm: 2.2686e-0606 - val_loss: 0.6931 - val_accuracy: 0.5000 - val_net_norm: 2.4502e-06
Epoch 2/30
1/8 [==>...........................] - ETA: 24s - loss: 0.6931 - accuracy: 0.2000 - net_norm: 1.0251e-06-05 - val_loss: 0.6930 - val_accuracy: 0.5000 - val_net_norm: 3.8324e-05
Epoch 3/30
8/8 [==============================] - 29s 4s/step - loss: 0.6928 - accuracy: 0.5000 - net_norm: 9.7617e-05 - val_loss: 0.6926 - val_accuracy: 0.5000 - val_net_norm: 1.8755e-04
Epoch 4/30
7/8 [=========================>....] - ETA: 3s - loss: 0.6924 - accuracy: 0.5286 - net_norm: 2.7150e-04 -04 - val_loss: 0.6922 - val_accuracy: 0.5000 - val_net_norm: 3.3740e-04
Epoch 5/30
7/8 [=========================>....] - ETA: 3s - loss: 0.6920 - accuracy: 0.5286 - net_norm: 4.2852e-04 -04 - val_loss: 0.6918 - val_accuracy: 0.5000 - val_net_norm: 4.7818e-04
Epoch 6/30
8/8 [==============================] - 29s 4s/step - loss: 0.6916 - accuracy: 0.5000 - net_norm: 5.8360e-04 - val_loss: 0.6915 - val_accuracy: 0.5000 - val_net_norm: 6.2660e-04
Epoch 7/30
8/8 [==============================] - 28s 4s/step - loss: 0.6912 - accuracy: 0.5000 - net_norm: 7.2425e-04 - val_loss: 0.6910 - val_accuracy: 0.5000 - val_net_norm: 8.5669e-04
Epoch 8/30
8/8 [==============================] - 28s 4s/step - loss: 0.6906 - accuracy: 0.5000 - net_norm: 9.4228e-04 - val_loss: 0.6902 - val_accuracy: 0.5000 - val_net_norm: 0.0011
Epoch 9/30
8/8 [==============================] - 28s 4s/step - loss: 0.6896 - accuracy: 0.5000 - net_norm: 0.0012 - val_loss: 0.6893 - val_accuracy: 0.5000 - val_net_norm: 0.0015
Epoch 10/30
6/8 [=====================>........] - ETA: 5s - loss: 0.6884 - accuracy: 0.5000 - net_norm: 0.0015     - val_loss: 0.6881 - val_accuracy: 0.5000 - val_net_norm: 0.0021
Epoch 11/30
5/8 [=================>............] - ETA: 9s - loss: 0.6868 - accuracy: 0.5000 - net_norm: 0.0020 022 - val_loss: 0.6864 - val_accuracy: 0.5000 - val_net_norm: 0.0031
Epoch 12/30
2/8 [======>.......................] - ETA: 18s - loss: 0.6842 - accuracy: 0.5500 - net_norm: 0.0029031 - val_loss: 0.6831 - val_accuracy: 0.5000 - val_net_norm: 0.0043
Epoch 13/30
1/8 [==>...........................] - ETA: 20s - loss: 0.6797 - accuracy: 0.6000 - net_norm: 0.0041044 - val_loss: 0.6780 - val_accuracy: 0.5000 - val_net_norm: 0.0060
Epoch 14/30
8/8 [==============================] - 28s 4s/step - loss: 0.6730 - accuracy: 0.5000 - net_norm: 0.0063 - val_loss: 0.6717 - val_accuracy: 0.5000 - val_net_norm: 0.0087
Epoch 15/30
8/8 [==============================] - 29s 4s/step - loss: 0.6650 - accuracy: 0.5000 - net_norm: 0.0090 - val_loss: 0.6612 - val_accuracy: 0.5000 - val_net_norm: 0.0129
Epoch 16/30
2/8 [======>.......................] - ETA: 18s - loss: 0.6567 - accuracy: 0.5000 - net_norm: 0.0118136 - val_loss: 0.6453 - val_accuracy: 0.5000 - val_net_norm: 0.0187
Epoch 17/30
8/8 [==============================] - 29s 4s/step - loss: 0.6332 - accuracy: 0.5000 - net_norm: 0.0196 - val_loss: 0.6245 - val_accuracy: 0.5000 - val_net_norm: 0.0283
Epoch 18/30
8/8 [==============================] - 28s 4s/step - loss: 0.6074 - accuracy: 0.5000 - net_norm: 0.0292 - val_loss: 0.5961 - val_accuracy: 0.5000 - val_net_norm: 0.0413
Epoch 19/30
8/8 [==============================] - 28s 4s/step - loss: 0.5728 - accuracy: 0.5000 - net_norm: 0.0445 - val_loss: 0.5603 - val_accuracy: 0.5000 - val_net_norm: 0.0604
Epoch 20/30
6/8 [=====================>........] - ETA: 5s - loss: 0.5524 - accuracy: 0.4500 - net_norm: 0.0562 669 - val_loss: 0.5171 - val_accuracy: 0.5000 - val_net_norm: 0.0901
Epoch 21/30
8/8 [==============================] - 28s 4s/step - loss: 0.4854 - accuracy: 0.5000 - net_norm: 0.0958 - val_loss: 0.4801 - val_accuracy: 0.5000 - val_net_norm: 0.1297
Epoch 22/30
7/8 [=========================>....] - ETA: 2s - loss: 0.4403 - accuracy: 0.5143 - net_norm: 0.1374 360 - val_loss: 0.4542 - val_accuracy: 0.5000 - val_net_norm: 0.1727
Epoch 23/30
1/8 [==>...........................] - ETA: 22s - loss: 0.5217 - accuracy: 0.3000 - net_norm: 0.1092767 - val_loss: 0.4364 - val_accuracy: 0.5000 - val_net_norm: 0.2099
Epoch 24/30
8/8 [==============================] - 29s 4s/step - loss: 0.4029 - accuracy: 0.5000 - net_norm: 0.2088 - val_loss: 0.4198 - val_accuracy: 0.5000 - val_net_norm: 0.2432
Epoch 25/30
8/8 [==============================] - 28s 4s/step - loss: 0.3923 - accuracy: 0.5000 - net_norm: 0.2409 - val_loss: 0.4154 - val_accuracy: 0.5000 - val_net_norm: 0.2690
Epoch 26/30
8/8 [==============================] - 28s 4s/step - loss: 0.3861 - accuracy: 0.5000 - net_norm: 0.2633 - val_loss: 0.4051 - val_accuracy: 0.5000 - val_net_norm: 0.2876
Epoch 27/30
8/8 [==============================] - 28s 4s/step - loss: 0.3796 - accuracy: 0.5000 - net_norm: 0.2791 - val_loss: 0.3987 - val_accuracy: 0.5000 - val_net_norm: 0.3015
Epoch 28/30
5/8 [=================>............] - ETA: 8s - loss: 0.3728 - accuracy: 0.5200 - net_norm: 0.2987 890 - val_loss: 0.3958 - val_accuracy: 0.5000 - val_net_norm: 0.3085
Epoch 29/30
7/8 [=========================>....] - ETA: 3s - loss: 0.3751 - accuracy: 0.5000 - net_norm: 0.3025 