2022-03-11 05:14:27.347919: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64/nvidia:
2022-03-11 05:14:27.348197: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-03-11 05:14:27.348328: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cac041): /proc/driver/nvidia/version does not exist
2022-03-11 05:14:27.350349: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/30
1/8 [==>...........................] - ETA: 2:00 - loss: 0.5215 - accuracy: 0.4000 - net_norm: 0.281361 - val_loss: 0.3997 - val_accuracy: 0.6000 - val_net_norm: 0.4335
Epoch 2/30
1/8 [==>...........................] - ETA: 40s - loss: 0.5924 - accuracy: 0.3000 - net_norm: 0.1762537 - val_loss: 0.3792 - val_accuracy: 0.7000 - val_net_norm: 0.4447
Epoch 3/30
2/8 [======>.......................] - ETA: 35s - loss: 0.4068 - accuracy: 0.7500 - net_norm: 0.4283697 - val_loss: 0.3631 - val_accuracy: 0.7000 - val_net_norm: 0.4624
Epoch 4/30
2/8 [======>.......................] - ETA: 32s - loss: 0.4259 - accuracy: 0.6500 - net_norm: 0.4840897 - val_loss: 0.3571 - val_accuracy: 0.7000 - val_net_norm: 0.4816
Epoch 5/30
2/8 [======>.......................] - ETA: 32s - loss: 0.3554 - accuracy: 0.8500 - net_norm: 0.4700087 - val_loss: 0.3259 - val_accuracy: 0.9500 - val_net_norm: 0.5056
Epoch 6/30
1/8 [==>...........................] - ETA: 38s - loss: 0.2850 - accuracy: 1.0000 - net_norm: 0.5450343 - val_loss: 0.3072 - val_accuracy: 1.0000 - val_net_norm: 0.5416
Epoch 7/30
1/8 [==>...........................] - ETA: 40s - loss: 0.3000 - accuracy: 1.0000 - net_norm: 0.5961778 - val_loss: 0.3014 - val_accuracy: 0.9500 - val_net_norm: 0.5672
Epoch 8/30
1/8 [==>...........................] - ETA: 38s - loss: 0.2657 - accuracy: 1.0000 - net_norm: 0.6361095 - val_loss: 0.2913 - val_accuracy: 1.0000 - val_net_norm: 0.5872
Epoch 9/30
1/8 [==>...........................] - ETA: 38s - loss: 0.2436 - accuracy: 1.0000 - net_norm: 0.6626266 - val_loss: 0.2771 - val_accuracy: 1.0000 - val_net_norm: 0.6040
Epoch 10/30
2/8 [======>.......................] - ETA: 33s - loss: 0.1706 - accuracy: 1.0000 - net_norm: 0.6508490 - val_loss: 0.2524 - val_accuracy: 1.0000 - val_net_norm: 0.6251
Epoch 11/30
2/8 [======>.......................] - ETA: 32s - loss: 0.2073 - accuracy: 1.0000 - net_norm: 0.7083762 - val_loss: 0.2005 - val_accuracy: 1.0000 - val_net_norm: 0.6584
Epoch 12/30
2/8 [======>.......................] - ETA: 32s - loss: 0.1729 - accuracy: 1.0000 - net_norm: 0.7212054 - val_loss: 0.1637 - val_accuracy: 1.0000 - val_net_norm: 0.7116
Epoch 13/30
2/8 [======>.......................] - ETA: 34s - loss: 0.0912 - accuracy: 1.0000 - net_norm: 0.8051665 - val_loss: 0.1520 - val_accuracy: 1.0000 - val_net_norm: 0.7570
Epoch 14/30
1/8 [==>...........................] - ETA: 37s - loss: 0.0390 - accuracy: 1.0000 - net_norm: 0.9047173 - val_loss: 0.1417 - val_accuracy: 1.0000 - val_net_norm: 0.7789
Epoch 15/30
1/8 [==>...........................] - ETA: 37s - loss: 0.0329 - accuracy: 1.0000 - net_norm: 0.9012507 - val_loss: 0.1314 - val_accuracy: 1.0000 - val_net_norm: 0.7904
Epoch 16/30
1/8 [==>...........................] - ETA: 37s - loss: 0.1764 - accuracy: 1.0000 - net_norm: 0.6947560 - val_loss: 0.1248 - val_accuracy: 1.0000 - val_net_norm: 0.7968
Epoch 17/30
2/8 [======>.......................] - ETA: 31s - loss: 0.0649 - accuracy: 1.0000 - net_norm: 0.8662588 - val_loss: 0.1206 - val_accuracy: 1.0000 - val_net_norm: 0.8015
Epoch 18/30
2/8 [======>.......................] - ETA: 31s - loss: 0.0537 - accuracy: 1.0000 - net_norm: 0.8233637 - val_loss: 0.1158 - val_accuracy: 1.0000 - val_net_norm: 0.8072
Epoch 19/30
2/8 [======>.......................] - ETA: 32s - loss: 0.0618 - accuracy: 1.0000 - net_norm: 0.8444727 - val_loss: 0.1097 - val_accuracy: 1.0000 - val_net_norm: 0.8154
Epoch 20/30
2/8 [======>.......................] - ETA: 31s - loss: 0.0909 - accuracy: 1.0000 - net_norm: 0.7820856 - val_loss: 0.1030 - val_accuracy: 1.0000 - val_net_norm: 0.8239
Epoch 21/30
2/8 [======>.......................] - ETA: 31s - loss: 0.0629 - accuracy: 1.0000 - net_norm: 0.8275890 - val_loss: 0.0980 - val_accuracy: 1.0000 - val_net_norm: 0.8265
Epoch 22/30
2/8 [======>.......................] - ETA: 31s - loss: 0.0391 - accuracy: 1.0000 - net_norm: 0.8992889 - val_loss: 0.0905 - val_accuracy: 1.0000 - val_net_norm: 0.8310
Epoch 23/30
1/8 [==>...........................] - ETA: 37s - loss: 0.0256 - accuracy: 1.0000 - net_norm: 0.8822874 - val_loss: 0.0873 - val_accuracy: 1.0000 - val_net_norm: 0.8316
Epoch 24/30
3/8 [==========>...................] - ETA: 27s - loss: 0.0330 - accuracy: 1.0000 - net_norm: 0.8816875 - val_loss: 0.0820 - val_accuracy: 1.0000 - val_net_norm: 0.8351
Epoch 25/30
2/8 [======>.......................] - ETA: 31s - loss: 0.0365 - accuracy: 1.0000 - net_norm: 0.8881906 - val_loss: 0.0800 - val_accuracy: 1.0000 - val_net_norm: 0.8380
Epoch 26/30
8/8 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 1.0000 - net_norm: 0.8917 917 - val_loss: 0.0783 - val_accuracy: 1.0000 - val_net_norm: 0.8384
Epoch 27/30
4/8 [==============>...............] - ETA: 21s - loss: 0.0451 - accuracy: 1.0000 - net_norm: 0.9291885 - val_loss: 0.0765 - val_accuracy: 1.0000 - val_net_norm: 0.8382
Epoch 28/30
1/8 [==>...........................] - ETA: 37s - loss: 0.0198 - accuracy: 1.0000 - net_norm: 0.8950904 - val_loss: 0.0733 - val_accuracy: 1.0000 - val_net_norm: 0.8418
Epoch 29/30
2/8 [======>.......................] - ETA: 34s - loss: 0.0555 - accuracy: 1.0000 - net_norm: 0.9090948 - val_loss: 0.0684 - val_accuracy: 1.0000 - val_net_norm: 0.8467
