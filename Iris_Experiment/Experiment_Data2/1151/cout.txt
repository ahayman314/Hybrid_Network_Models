2022-03-11 04:21:27.811615: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64/nvidia:
2022-03-11 04:21:27.811839: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-03-11 04:21:27.811934: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cac032): /proc/driver/nvidia/version does not exist
2022-03-11 04:21:27.813436: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/30
1/8 [==>...........................] - ETA: 1:00 - loss: 1.1624 - accuracy: 0.3000 - net_norm: 0.596133 - val_loss: 0.3520 - val_accuracy: 0.9000 - val_net_norm: 0.6787
Epoch 2/30
4/8 [==============>...............] - ETA: 9s - loss: 0.2954 - accuracy: 0.9750 - net_norm: 0.6446 898 - val_loss: 0.3400 - val_accuracy: 0.9000 - val_net_norm: 0.6804
Epoch 3/30
3/8 [==========>...................] - ETA: 12s - loss: 0.2551 - accuracy: 1.0000 - net_norm: 0.6792015 - val_loss: 0.3578 - val_accuracy: 0.9500 - val_net_norm: 0.6913
Epoch 4/30
1/8 [==>...........................] - ETA: 19s - loss: 0.1847 - accuracy: 1.0000 - net_norm: 0.8928153 - val_loss: 0.2899 - val_accuracy: 0.9500 - val_net_norm: 0.7067
Epoch 5/30
4/8 [==============>...............] - ETA: 10s - loss: 0.1888 - accuracy: 1.0000 - net_norm: 0.7515343 - val_loss: 0.2155 - val_accuracy: 1.0000 - val_net_norm: 0.7328
Epoch 6/30
6/8 [=====================>........] - ETA: 5s - loss: 0.1466 - accuracy: 1.0000 - net_norm: 0.7758 673 - val_loss: 0.1685 - val_accuracy: 1.0000 - val_net_norm: 0.7680
Epoch 7/30
8/8 [==============================] - 23s 3s/step - loss: 0.1273 - accuracy: 1.0000 - net_norm: 0.8088 - val_loss: 0.1446 - val_accuracy: 1.0000 - val_net_norm: 0.8089
Epoch 8/30
8/8 [==============================] - 23s 3s/step - loss: 0.1085 - accuracy: 1.0000 - net_norm: 0.8506 - val_loss: 0.1229 - val_accuracy: 1.0000 - val_net_norm: 0.8411
Epoch 9/30
8/8 [==============================] - 23s 3s/step - loss: 0.0968 - accuracy: 1.0000 - net_norm: 0.8809 - val_loss: 0.1088 - val_accuracy: 1.0000 - val_net_norm: 0.8579
Epoch 10/30
8/8 [==============================] - 22s 3s/step - loss: 0.0908 - accuracy: 1.0000 - net_norm: 0.8943 - val_loss: 0.0989 - val_accuracy: 1.0000 - val_net_norm: 0.8654
Epoch 11/30
8/8 [==============================] - 23s 3s/step - loss: 0.0840 - accuracy: 1.0000 - net_norm: 0.8990 - val_loss: 0.0933 - val_accuracy: 1.0000 - val_net_norm: 0.8657
Epoch 12/30
7/8 [=========================>....] - ETA: 2s - loss: 0.0834 - accuracy: 1.0000 - net_norm: 0.9012 986 - val_loss: 0.0918 - val_accuracy: 1.0000 - val_net_norm: 0.8621
Epoch 13/30
8/8 [==============================] - 23s 3s/step - loss: 0.0788 - accuracy: 1.0000 - net_norm: 0.8937 - val_loss: 0.0927 - val_accuracy: 1.0000 - val_net_norm: 0.8586
Epoch 14/30
8/8 [==============================] - 22s 3s/step - loss: 0.0775 - accuracy: 1.0000 - net_norm: 0.8900 - val_loss: 0.0939 - val_accuracy: 1.0000 - val_net_norm: 0.8567
Epoch 15/30
8/8 [==============================] - 23s 3s/step - loss: 0.0763 - accuracy: 1.0000 - net_norm: 0.8903 - val_loss: 0.0938 - val_accuracy: 1.0000 - val_net_norm: 0.8578
Epoch 16/30
3/8 [==========>...................] - ETA: 12s - loss: 0.0923 - accuracy: 1.0000 - net_norm: 0.8594898 - val_loss: 0.0947 - val_accuracy: 1.0000 - val_net_norm: 0.8564
Epoch 17/30
2/8 [======>.......................] - ETA: 14s - loss: 0.0764 - accuracy: 1.0000 - net_norm: 0.9010887 - val_loss: 0.0931 - val_accuracy: 1.0000 - val_net_norm: 0.8560
Epoch 18/30
8/8 [==============================] - 23s 3s/step - loss: 0.0715 - accuracy: 1.0000 - net_norm: 0.8890 - val_loss: 0.0928 - val_accuracy: 1.0000 - val_net_norm: 0.8561
Epoch 19/30
8/8 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 1.0000 - net_norm: 0.8885 885 - val_loss: 0.0932 - val_accuracy: 1.0000 - val_net_norm: 0.8556
Epoch 20/30
1/8 [==>...........................] - ETA: 19s - loss: 0.0921 - accuracy: 1.0000 - net_norm: 0.7686885 - val_loss: 0.0924 - val_accuracy: 1.0000 - val_net_norm: 0.8551
Epoch 21/30
8/8 [==============================] - 23s 3s/step - loss: 0.0703 - accuracy: 1.0000 - net_norm: 0.8861 - val_loss: 0.0926 - val_accuracy: 1.0000 - val_net_norm: 0.8531
Epoch 22/30
6/8 [=====================>........] - ETA: 5s - loss: 0.0762 - accuracy: 1.0000 - net_norm: 0.8804 846 - val_loss: 0.0916 - val_accuracy: 1.0000 - val_net_norm: 0.8532
Epoch 23/30
8/8 [==============================] - 24s 3s/step - loss: 0.0698 - accuracy: 1.0000 - net_norm: 0.8859 - val_loss: 0.0915 - val_accuracy: 1.0000 - val_net_norm: 0.8537
Epoch 24/30
2/8 [======>.......................] - ETA: 13s - loss: 0.0678 - accuracy: 1.0000 - net_norm: 0.8492856 - val_loss: 0.0912 - val_accuracy: 1.0000 - val_net_norm: 0.8530
Epoch 25/30
3/8 [==========>...................] - ETA: 11s - loss: 0.0572 - accuracy: 1.0000 - net_norm: 0.9056838 - val_loss: 0.0899 - val_accuracy: 1.0000 - val_net_norm: 0.8526
Epoch 26/30
5/8 [=================>............] - ETA: 7s - loss: 0.0737 - accuracy: 1.0000 - net_norm: 0.8697 830 - val_loss: 0.0905 - val_accuracy: 1.0000 - val_net_norm: 0.8516
Epoch 27/30
8/8 [==============================] - 23s 3s/step - loss: 0.0687 - accuracy: 1.0000 - net_norm: 0.8811 - val_loss: 0.0911 - val_accuracy: 1.0000 - val_net_norm: 0.8500
Epoch 28/30
6/8 [=====================>........] - ETA: 4s - loss: 0.0610 - accuracy: 1.0000 - net_norm: 0.9141 808 - val_loss: 0.0899 - val_accuracy: 1.0000 - val_net_norm: 0.8513
Epoch 29/30
8/8 [==============================] - 22s 3s/step - loss: 0.0679 - accuracy: 1.0000 - net_norm: 0.8822 - val_loss: 0.0899 - val_accuracy: 1.0000 - val_net_norm: 0.8503
