2022-03-11 04:49:35.442100: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64/nvidia:
2022-03-11 04:49:35.442313: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-03-11 04:49:35.442419: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cac050): /proc/driver/nvidia/version does not exist
2022-03-11 04:49:35.444098: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/30
3/8 [==========>...................] - ETA: 13s - loss: 0.6614 - accuracy: 0.4667 - net_norm: 0.0317 95 - val_loss: 0.6233 - val_accuracy: 0.5000 - val_net_norm: 0.0447
Epoch 2/30
1/8 [==>...........................] - ETA: 20s - loss: 0.6718 - accuracy: 0.2000 - net_norm: 0.0217477 - val_loss: 0.6053 - val_accuracy: 0.5000 - val_net_norm: 0.0536
Epoch 3/30
2/8 [======>.......................] - ETA: 17s - loss: 0.5875 - accuracy: 0.5000 - net_norm: 0.0484562 - val_loss: 0.5978 - val_accuracy: 0.5000 - val_net_norm: 0.0647
Epoch 4/30
4/8 [==============>...............] - ETA: 11s - loss: 0.5715 - accuracy: 0.5500 - net_norm: 0.0713667 - val_loss: 0.5860 - val_accuracy: 0.5000 - val_net_norm: 0.0778
Epoch 5/30
2/8 [======>.......................] - ETA: 16s - loss: 0.5603 - accuracy: 0.5000 - net_norm: 0.0710792 - val_loss: 0.5759 - val_accuracy: 0.5000 - val_net_norm: 0.0912
Epoch 6/30
3/8 [==========>...................] - ETA: 14s - loss: 0.5230 - accuracy: 0.5667 - net_norm: 0.0952915 - val_loss: 0.5658 - val_accuracy: 0.5000 - val_net_norm: 0.1061
Epoch 7/30
4/8 [==============>...............] - ETA: 11s - loss: 0.5592 - accuracy: 0.4750 - net_norm: 0.1045061 - val_loss: 0.5566 - val_accuracy: 0.5000 - val_net_norm: 0.1228
Epoch 8/30
2/8 [======>.......................] - ETA: 17s - loss: 0.4890 - accuracy: 0.6000 - net_norm: 0.1367207 - val_loss: 0.5435 - val_accuracy: 0.5000 - val_net_norm: 0.1369
Epoch 9/30
3/8 [==========>...................] - ETA: 13s - loss: 0.4876 - accuracy: 0.5000 - net_norm: 0.1206336 - val_loss: 0.5363 - val_accuracy: 0.5000 - val_net_norm: 0.1516
Epoch 10/30
1/8 [==>...........................] - ETA: 19s - loss: 0.5862 - accuracy: 0.3000 - net_norm: 0.0943504 - val_loss: 0.5417 - val_accuracy: 0.5000 - val_net_norm: 0.1736
Epoch 11/30
2/8 [======>.......................] - ETA: 15s - loss: 0.3687 - accuracy: 0.6500 - net_norm: 0.1920667 - val_loss: 0.5379 - val_accuracy: 0.5000 - val_net_norm: 0.1884
Epoch 12/30
3/8 [==========>...................] - ETA: 13s - loss: 0.4573 - accuracy: 0.5333 - net_norm: 0.1826781 - val_loss: 0.5301 - val_accuracy: 0.5000 - val_net_norm: 0.2001
Epoch 13/30
1/8 [==>...........................] - ETA: 22s - loss: 0.3693 - accuracy: 0.6000 - net_norm: 0.1957896 - val_loss: 0.5322 - val_accuracy: 0.5000 - val_net_norm: 0.2140
Epoch 14/30
2/8 [======>.......................] - ETA: 15s - loss: 0.4450 - accuracy: 0.6000 - net_norm: 0.2433996 - val_loss: 0.5382 - val_accuracy: 0.5000 - val_net_norm: 0.2234
Epoch 15/30
1/8 [==>...........................] - ETA: 18s - loss: 0.3399 - accuracy: 0.7000 - net_norm: 0.2777049 - val_loss: 0.5470 - val_accuracy: 0.5000 - val_net_norm: 0.2226
Epoch 16/30
3/8 [==========>...................] - ETA: 14s - loss: 0.4487 - accuracy: 0.5333 - net_norm: 0.2150986 - val_loss: 0.5320 - val_accuracy: 0.5000 - val_net_norm: 0.2169
Epoch 17/30
8/8 [==============================] - 26s 3s/step - loss: 0.4526 - accuracy: 0.5000 - net_norm: 0.1998 - val_loss: 0.5355 - val_accuracy: 0.5000 - val_net_norm: 0.2272
Epoch 18/30
2/8 [======>.......................] - ETA: 17s - loss: 0.5567 - accuracy: 0.3000 - net_norm: 0.1335125 - val_loss: 0.5282 - val_accuracy: 0.5000 - val_net_norm: 0.2369
Epoch 19/30
8/8 [==============================] - 28s 4s/step - loss: 0.4414 - accuracy: 0.5000 - net_norm: 0.2185 - val_loss: 0.5343 - val_accuracy: 0.5000 - val_net_norm: 0.2467
Epoch 20/30
3/8 [==========>...................] - ETA: 14s - loss: 0.5082 - accuracy: 0.4333 - net_norm: 0.2097327 - val_loss: 0.5390 - val_accuracy: 0.5000 - val_net_norm: 0.2654
Epoch 21/30
2/8 [======>.......................] - ETA: 16s - loss: 0.4335 - accuracy: 0.4500 - net_norm: 0.2091488 - val_loss: 0.5201 - val_accuracy: 0.5500 - val_net_norm: 0.2834
Epoch 22/30
8/8 [==============================] - 26s 3s/step - loss: 0.4261 - accuracy: 0.6125 - net_norm: 0.2648 - val_loss: 0.5119 - val_accuracy: 0.7500 - val_net_norm: 0.3050
Epoch 23/30
1/8 [==>...........................] - ETA: 19s - loss: 0.5463 - accuracy: 0.6000 - net_norm: 0.1952981 - val_loss: 0.5886 - val_accuracy: 0.5000 - val_net_norm: 0.3447
Epoch 24/30
8/8 [==============================] - 27s 3s/step - loss: 0.4248 - accuracy: 0.6750 - net_norm: 0.3180 - val_loss: 0.4869 - val_accuracy: 0.8500 - val_net_norm: 0.3505
Epoch 25/30
5/8 [=================>............] - ETA: 8s - loss: 0.4049 - accuracy: 0.9400 - net_norm: 0.3251 349 - val_loss: 0.5029 - val_accuracy: 0.8500 - val_net_norm: 0.3929
Epoch 26/30
8/8 [==============================] - ETA: 0s - loss: 0.3767 - accuracy: 0.9125 - net_norm: 0.3863 863 - val_loss: 0.4430 - val_accuracy: 0.8500 - val_net_norm: 0.4410
Epoch 27/30
5/8 [=================>............] - ETA: 8s - loss: 0.3215 - accuracy: 0.9800 - net_norm: 0.4685 485 - val_loss: 0.4450 - val_accuracy: 0.8500 - val_net_norm: 0.5239
Epoch 28/30
5/8 [=================>............] - ETA: 8s - loss: 0.2502 - accuracy: 0.9800 - net_norm: 0.5717 657 - val_loss: 0.3138 - val_accuracy: 0.8500 - val_net_norm: 0.6327
Epoch 29/30
8/8 [==============================] - ETA: 0s - loss: 0.1930 - accuracy: 0.9375 - net_norm: 0.6760 760 - val_loss: 0.2849 - val_accuracy: 0.9500 - val_net_norm: 0.6959
