2022-03-11 03:22:19.451644: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64/nvidia:
2022-03-11 03:22:19.451837: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-03-11 03:22:19.451916: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cac042): /proc/driver/nvidia/version does not exist
2022-03-11 03:22:19.453963: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/30
1/8 [==>...........................] - ETA: 1:58 - loss: 0.7525 - accuracy: 0.3000 - net_norm: 0.469687 - val_loss: 0.3674 - val_accuracy: 0.8500 - val_net_norm: 0.5856
Epoch 2/30
5/8 [=================>............] - ETA: 14s - loss: 0.3620 - accuracy: 0.8800 - net_norm: 0.5586623 - val_loss: 0.3084 - val_accuracy: 1.0000 - val_net_norm: 0.5790
Epoch 3/30
6/8 [=====================>........] - ETA: 9s - loss: 0.3163 - accuracy: 1.0000 - net_norm: 0.5777 675 - val_loss: 0.2983 - val_accuracy: 1.0000 - val_net_norm: 0.5917
Epoch 4/30
8/8 [==============================] - 43s 5s/step - loss: 0.2918 - accuracy: 0.9875 - net_norm: 0.5809 - val_loss: 0.2645 - val_accuracy: 1.0000 - val_net_norm: 0.6073
Epoch 5/30
2/8 [======>.......................] - ETA: 26s - loss: 0.2449 - accuracy: 1.0000 - net_norm: 0.5839025 - val_loss: 0.2375 - val_accuracy: 1.0000 - val_net_norm: 0.6325
Epoch 6/30
3/8 [==========>...................] - ETA: 22s - loss: 0.1787 - accuracy: 1.0000 - net_norm: 0.7005335 - val_loss: 0.2045 - val_accuracy: 1.0000 - val_net_norm: 0.6615
Epoch 7/30
1/8 [==>...........................] - ETA: 30s - loss: 0.2044 - accuracy: 1.0000 - net_norm: 0.6468800 - val_loss: 0.1715 - val_accuracy: 1.0000 - val_net_norm: 0.6981
Epoch 8/30
8/8 [==============================] - 42s 5s/step - loss: 0.1279 - accuracy: 1.0000 - net_norm: 0.7362 - val_loss: 0.1502 - val_accuracy: 1.0000 - val_net_norm: 0.7436
Epoch 9/30
3/8 [==========>...................] - ETA: 23s - loss: 0.0860 - accuracy: 1.0000 - net_norm: 0.7874994 - val_loss: 0.1357 - val_accuracy: 1.0000 - val_net_norm: 0.7806
Epoch 10/30
7/8 [=========================>....] - ETA: 4s - loss: 0.0748 - accuracy: 1.0000 - net_norm: 0.8370 494 - val_loss: 0.1245 - val_accuracy: 1.0000 - val_net_norm: 0.8029
Epoch 11/30
3/8 [==========>...................] - ETA: 23s - loss: 0.0487 - accuracy: 1.0000 - net_norm: 0.8838766 - val_loss: 0.1147 - val_accuracy: 1.0000 - val_net_norm: 0.8137
Epoch 12/30
8/8 [==============================] - 42s 5s/step - loss: 0.0600 - accuracy: 1.0000 - net_norm: 0.8849 - val_loss: 0.1038 - val_accuracy: 1.0000 - val_net_norm: 0.8206
Epoch 13/30
5/8 [=================>............] - ETA: 13s - loss: 0.0498 - accuracy: 1.0000 - net_norm: 0.8836819 - val_loss: 0.0979 - val_accuracy: 1.0000 - val_net_norm: 0.8218
Epoch 14/30
1/8 [==>...........................] - ETA: 31s - loss: 0.0477 - accuracy: 1.0000 - net_norm: 0.9495794 - val_loss: 0.0929 - val_accuracy: 1.0000 - val_net_norm: 0.8250
Epoch 15/30
2/8 [======>.......................] - ETA: 26s - loss: 0.0513 - accuracy: 1.0000 - net_norm: 0.9066842 - val_loss: 0.0840 - val_accuracy: 1.0000 - val_net_norm: 0.8343
Epoch 16/30
2/8 [======>.......................] - ETA: 26s - loss: 0.0682 - accuracy: 1.0000 - net_norm: 0.8388922 - val_loss: 0.0766 - val_accuracy: 1.0000 - val_net_norm: 0.8429
Epoch 17/30
1/8 [==>...........................] - ETA: 30s - loss: 0.0567 - accuracy: 1.0000 - net_norm: 0.8894967 - val_loss: 0.0720 - val_accuracy: 1.0000 - val_net_norm: 0.8478
Epoch 18/30
1/8 [==>...........................] - ETA: 33s - loss: 0.0300 - accuracy: 1.0000 - net_norm: 0.8891980 - val_loss: 0.0681 - val_accuracy: 1.0000 - val_net_norm: 0.8503
Epoch 19/30
1/8 [==>...........................] - ETA: 31s - loss: 0.0662 - accuracy: 1.0000 - net_norm: 0.8512991 - val_loss: 0.0642 - val_accuracy: 1.0000 - val_net_norm: 0.8555
Epoch 20/30
2/8 [======>.......................] - ETA: 26s - loss: 0.0657 - accuracy: 1.0000 - net_norm: 0.8282033 - val_loss: 0.0610 - val_accuracy: 1.0000 - val_net_norm: 0.8632
Epoch 21/30
2/8 [======>.......................] - ETA: 28s - loss: 0.0383 - accuracy: 1.0000 - net_norm: 0.8567056 - val_loss: 0.0600 - val_accuracy: 1.0000 - val_net_norm: 0.8656
Epoch 22/30
2/8 [======>.......................] - ETA: 26s - loss: 0.0430 - accuracy: 1.0000 - net_norm: 0.9181055 - val_loss: 0.0579 - val_accuracy: 1.0000 - val_net_norm: 0.8707
Epoch 23/30
1/8 [==>...........................] - ETA: 33s - loss: 0.0294 - accuracy: 1.0000 - net_norm: 0.8994065 - val_loss: 0.0572 - val_accuracy: 1.0000 - val_net_norm: 0.8738
Epoch 24/30
1/8 [==>...........................] - ETA: 30s - loss: 0.0479 - accuracy: 1.0000 - net_norm: 0.8781082 - val_loss: 0.0554 - val_accuracy: 1.0000 - val_net_norm: 0.8778
Epoch 25/30
1/8 [==>...........................] - ETA: 32s - loss: 0.0345 - accuracy: 1.0000 - net_norm: 0.9148092 - val_loss: 0.0549 - val_accuracy: 1.0000 - val_net_norm: 0.8811
Epoch 26/30
2/8 [======>.......................] - ETA: 26s - loss: 0.0375 - accuracy: 1.0000 - net_norm: 0.9210089 - val_loss: 0.0539 - val_accuracy: 1.0000 - val_net_norm: 0.8813
Epoch 27/30
2/8 [======>.......................] - ETA: 26s - loss: 0.0476 - accuracy: 1.0000 - net_norm: 0.9337068 - val_loss: 0.0535 - val_accuracy: 1.0000 - val_net_norm: 0.8807
Epoch 28/30
2/8 [======>.......................] - ETA: 28s - loss: 0.0259 - accuracy: 1.0000 - net_norm: 0.9427071 - val_loss: 0.0531 - val_accuracy: 1.0000 - val_net_norm: 0.8828
Epoch 29/30
1/8 [==>...........................] - ETA: 30s - loss: 0.0279 - accuracy: 1.0000 - net_norm: 0.9755091 - val_loss: 0.0520 - val_accuracy: 1.0000 - val_net_norm: 0.8855
