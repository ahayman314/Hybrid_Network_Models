2022-03-11 05:24:56.712374: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64/nvidia:
2022-03-11 05:24:56.712494: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-03-11 05:24:56.712572: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cac062): /proc/driver/nvidia/version does not exist
2022-03-11 05:24:56.713893: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/30
3/8 [==========>...................] - ETA: 13s - loss: 0.7322 - accuracy: 0.4667 - net_norm: 0.2782903 - val_loss: 0.6309 - val_accuracy: 0.5000 - val_net_norm: 0.2776
Epoch 2/30
1/8 [==>...........................] - ETA: 19s - loss: 0.7938 - accuracy: 0.2000 - net_norm: 0.1664668 - val_loss: 0.6113 - val_accuracy: 0.9000 - val_net_norm: 0.2876
Epoch 3/30
3/8 [==========>...................] - ETA: 14s - loss: 0.5891 - accuracy: 0.9333 - net_norm: 0.2693937 - val_loss: 0.5861 - val_accuracy: 0.7000 - val_net_norm: 0.3377
Epoch 4/30
1/8 [==>...........................] - ETA: 18s - loss: 0.5453 - accuracy: 0.7000 - net_norm: 0.3855421 - val_loss: 0.5483 - val_accuracy: 0.9000 - val_net_norm: 0.3942
Epoch 5/30
2/8 [======>.......................] - ETA: 16s - loss: 0.4889 - accuracy: 1.0000 - net_norm: 0.3691964 - val_loss: 0.5252 - val_accuracy: 0.9000 - val_net_norm: 0.4516
Epoch 6/30
4/8 [==============>...............] - ETA: 10s - loss: 0.4581 - accuracy: 0.9500 - net_norm: 0.4351506 - val_loss: 0.4859 - val_accuracy: 0.9000 - val_net_norm: 0.5084
Epoch 7/30
1/8 [==>...........................] - ETA: 21s - loss: 0.3833 - accuracy: 1.0000 - net_norm: 0.5202101 - val_loss: 0.4573 - val_accuracy: 0.9000 - val_net_norm: 0.5775
Epoch 8/30
3/8 [==========>...................] - ETA: 13s - loss: 0.3546 - accuracy: 0.9667 - net_norm: 0.5985787 - val_loss: 0.4014 - val_accuracy: 0.9000 - val_net_norm: 0.6445
Epoch 9/30
1/8 [==>...........................] - ETA: 18s - loss: 0.3298 - accuracy: 1.0000 - net_norm: 0.6501433 - val_loss: 0.3696 - val_accuracy: 0.9000 - val_net_norm: 0.7063
Epoch 10/30
2/8 [======>.......................] - ETA: 16s - loss: 0.2859 - accuracy: 0.9500 - net_norm: 0.6583033 - val_loss: 0.3300 - val_accuracy: 0.9000 - val_net_norm: 0.7585
Epoch 11/30
4/8 [==============>...............] - ETA: 11s - loss: 0.2539 - accuracy: 1.0000 - net_norm: 0.7388553 - val_loss: 0.3175 - val_accuracy: 0.9000 - val_net_norm: 0.8071
Epoch 12/30
2/8 [======>.......................] - ETA: 15s - loss: 0.2550 - accuracy: 1.0000 - net_norm: 0.8077991 - val_loss: 0.2899 - val_accuracy: 0.9000 - val_net_norm: 0.8410
Epoch 13/30
3/8 [==========>...................] - ETA: 14s - loss: 0.1966 - accuracy: 1.0000 - net_norm: 0.8297316 - val_loss: 0.2778 - val_accuracy: 0.9000 - val_net_norm: 0.8674
Epoch 14/30
1/8 [==>...........................] - ETA: 19s - loss: 0.1647 - accuracy: 1.0000 - net_norm: 0.8743532 - val_loss: 0.2703 - val_accuracy: 0.9000 - val_net_norm: 0.8848
Epoch 15/30
2/8 [======>.......................] - ETA: 16s - loss: 0.1817 - accuracy: 1.0000 - net_norm: 0.9123745 - val_loss: 0.2752 - val_accuracy: 0.9000 - val_net_norm: 0.9033
Epoch 16/30
4/8 [==============>...............] - ETA: 11s - loss: 0.2158 - accuracy: 0.9750 - net_norm: 0.8805865 - val_loss: 0.2534 - val_accuracy: 0.9000 - val_net_norm: 0.9122
Epoch 17/30
2/8 [======>.......................] - ETA: 15s - loss: 0.1915 - accuracy: 1.0000 - net_norm: 0.9266974 - val_loss: 0.2622 - val_accuracy: 0.9000 - val_net_norm: 0.9212
Epoch 18/30
3/8 [==========>...................] - ETA: 14s - loss: 0.1599 - accuracy: 1.0000 - net_norm: 0.8766034 - val_loss: 0.2519 - val_accuracy: 0.9000 - val_net_norm: 0.9246
Epoch 19/30
1/8 [==>...........................] - ETA: 18s - loss: 0.3435 - accuracy: 0.9000 - net_norm: 0.8929075 - val_loss: 0.2595 - val_accuracy: 0.9000 - val_net_norm: 0.9305
Epoch 20/30
2/8 [======>.......................] - ETA: 14s - loss: 0.2395 - accuracy: 0.9500 - net_norm: 0.8804149 - val_loss: 0.2447 - val_accuracy: 0.9000 - val_net_norm: 0.9348
Epoch 21/30
1/8 [==>...........................] - ETA: 18s - loss: 0.1309 - accuracy: 1.0000 - net_norm: 0.8857232 - val_loss: 0.2380 - val_accuracy: 0.9000 - val_net_norm: 0.9400
Epoch 22/30
8/8 [==============================] - 26s 3s/step - loss: 0.1651 - accuracy: 0.9875 - net_norm: 0.9255 - val_loss: 0.2306 - val_accuracy: 0.9000 - val_net_norm: 0.9401
Epoch 23/30
2/8 [======>.......................] - ETA: 16s - loss: 0.1592 - accuracy: 1.0000 - net_norm: 0.9155254 - val_loss: 0.2469 - val_accuracy: 0.9000 - val_net_norm: 0.9408
Epoch 24/30
8/8 [==============================] - 25s 3s/step - loss: 0.1592 - accuracy: 0.9875 - net_norm: 0.9253 - val_loss: 0.2476 - val_accuracy: 0.9000 - val_net_norm: 0.9407
Epoch 25/30
4/8 [==============>...............] - ETA: 11s - loss: 0.1547 - accuracy: 1.0000 - net_norm: 0.9322285 - val_loss: 0.2300 - val_accuracy: 0.9000 - val_net_norm: 0.9414
Epoch 26/30
8/8 [==============================] - ETA: 0s - loss: 0.1544 - accuracy: 0.9875 - net_norm: 0.9284 284 - val_loss: 0.2369 - val_accuracy: 0.9000 - val_net_norm: 0.9403
Epoch 27/30
5/8 [=================>............] - ETA: 8s - loss: 0.1668 - accuracy: 0.9800 - net_norm: 0.9389 229 - val_loss: 0.2549 - val_accuracy: 0.9000 - val_net_norm: 0.9376
Epoch 28/30
3/8 [==========>...................] - ETA: 13s - loss: 0.1451 - accuracy: 1.0000 - net_norm: 0.9424253 - val_loss: 0.2404 - val_accuracy: 0.9000 - val_net_norm: 0.9406
Epoch 29/30
8/8 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.9875 - net_norm: 0.9321 321 - val_loss: 0.2572 - val_accuracy: 0.9000 - val_net_norm: 0.9443
