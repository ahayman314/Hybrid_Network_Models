{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6d093a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cca78b",
   "metadata": {},
   "source": [
    "# MNIST Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8512c0",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4405ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from MNIST dataset \n",
    "training_data = torchvision.datasets.MNIST(\"root\", train=True, download=True, transform=ToTensor())\n",
    "testing_data = torchvision.datasets.MNIST(\"root\", train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "860f6baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only do 0's and 1's\n",
    "#training_data.data = training_data.data[training_data.targets<=1]\n",
    "#training_data.targets = training_data.targets[training_data.targets<=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca0e3aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:\t  torch.Size([60000, 28, 28])\n",
      "Testing data size:\t  torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Display information on datasets\n",
    "print(\"Training data size:\\t \", training_data.data.size())\n",
    "print(\"Testing data size:\\t \", testing_data.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c3f747e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '5')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a sample\n",
    "plt.imshow(training_data.data[0])\n",
    "plt.title('%i' % training_data.targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f43abb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare subset of data and shuffle\n",
    "train_dataloader = DataLoader(training_data, batch_size = 1000, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_data, batch_size = 100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acc4536d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([1000, 1, 28, 28])\n",
      "torch.Size([1000, 784])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "# Showcase dataloader information\n",
    "for batch, (images, labels) in enumerate(train_dataloader): \n",
    "    print(batch)\n",
    "    print(images.size())\n",
    "    print(images.view(images.shape[0], -1).size())\n",
    "    print(labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5534746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "test = torch.nn.functional.one_hot(training_data.targets)\n",
    "print(test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2b0808",
   "metadata": {},
   "source": [
    "## Network Design and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51bc13b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1052, -0.3478], grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubits = 2\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def qnode(inputs, w0, w1, w2, w3):\n",
    "    qml.RX(inputs[0], wires=0)\n",
    "    qml.RX(inputs[1], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.Rot(*w0, wires=0)\n",
    "    qml.Rot(*w1, wires=1)\n",
    "    qml.RY(w2, wires=0)\n",
    "    qml.RY(w3, wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1))\n",
    "\n",
    "weight_shapes = {\"w0\": 3, \"w1\": 3, \"w2\": 1, \"w3\": 1}\n",
    "qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "\n",
    "qlayer(torch.Tensor([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b8ef4614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network \n",
    "# Great source: https://pennylane.ai/qml/demos/tutorial_qnn_module_torch.html\n",
    "# Note that in_channels = 1 because the input is a grayscale image\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(in_features=784, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=10),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        self.final = nn.Sequential(nn.Linear(in_features=10, out_features=10))\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.main(x)\n",
    "        x_split = torch.split(x, 2, dim=1)\n",
    "        x_split = list(x_split)\n",
    "        for i in range(len(x_split)): \n",
    "            x_split[i] = qlayer(x_split[i])\n",
    "        x = torch.cat(x_split, dim=1)\n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c0a602f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "    (5): LogSoftmax(dim=1)\n",
      "  )\n",
      "  (final): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# View neural network \n",
    "network = Net()\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bd8c84df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 128]         100,480\n",
      "              ReLU-2                  [-1, 128]               0\n",
      "            Linear-3                   [-1, 64]           8,256\n",
      "              ReLU-4                   [-1, 64]               0\n",
      "            Linear-5                   [-1, 10]             650\n",
      "        LogSoftmax-6                   [-1, 10]               0\n",
      "            Linear-7                   [-1, 10]             110\n",
      "================================================================\n",
      "Total params: 109,496\n",
      "Trainable params: 109,496\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.42\n",
      "Estimated Total Size (MB): 0.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(network, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a80de6",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7b3e5409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training routine\n",
    "def train(epochs):\n",
    "    epoch_list = []\n",
    "    accuracy_list = []\n",
    "    loss_list = []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        accuracy = 0\n",
    "        running_loss = 0\n",
    "\n",
    "        for batch_idx, (image, labels) in enumerate(train_dataloader):\n",
    "            output = network(image)                           # Find network output\n",
    "            loss = loss_function(output, labels)              # Compute loss\n",
    "\n",
    "            predicted = torch.max(output.data, 1)[1]          # Find predicted value\n",
    "            batch_corr = (predicted == labels).sum()          # Find number of correct values\n",
    "            batch_accuracy = (100*batch_corr / len(labels))    \n",
    "            accuracy+=batch_accuracy/60\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()                             # Clear gradients for this training step\n",
    "            loss.backward()                                   # Compute gradients from backpropagation \n",
    "            optimizer.step()                                  # Apply changes from gradients\n",
    "            print(\"Batch accuracy: %.2f\" % batch_accuracy)\n",
    "\n",
    "        print(\"Training accuracy: %.2f \\t Training loss: %.2f \" % (accuracy, running_loss))\n",
    "        epoch_list.append(epoch)\n",
    "        accuracy_list.append(accuracy)\n",
    "        loss_list.append(running_loss)\n",
    "    return epoch_list, accuracy_list, loss_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "14174f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 10.70\n",
      "Batch accuracy: 13.20\n",
      "Batch accuracy: 16.60\n",
      "Batch accuracy: 13.60\n",
      "Batch accuracy: 21.20\n",
      "Batch accuracy: 30.00\n",
      "Batch accuracy: 29.70\n",
      "Batch accuracy: 28.40\n",
      "Batch accuracy: 34.60\n",
      "Batch accuracy: 36.00\n",
      "Batch accuracy: 40.80\n",
      "Batch accuracy: 40.30\n",
      "Batch accuracy: 43.50\n",
      "Batch accuracy: 44.80\n",
      "Batch accuracy: 49.00\n",
      "Batch accuracy: 51.10\n",
      "Batch accuracy: 56.80\n",
      "Batch accuracy: 52.00\n",
      "Batch accuracy: 55.50\n",
      "Batch accuracy: 55.40\n",
      "Batch accuracy: 55.80\n",
      "Batch accuracy: 57.50\n",
      "Batch accuracy: 61.30\n",
      "Batch accuracy: 61.60\n",
      "Batch accuracy: 63.00\n",
      "Batch accuracy: 62.30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [112]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m loss_function \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(network\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m epochs, accuracy, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [111]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs)\u001b[0m\n\u001b[0;32m      8\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (image, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m---> 11\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m                           \u001b[38;5;66;03m# Find network output\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(output, labels)              \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(output\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]          \u001b[38;5;66;03m# Find predicted value\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [108]\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m x_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(x_split)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x_split)): \n\u001b[1;32m---> 26\u001b[0m     x_split[i] \u001b[38;5;241m=\u001b[39m \u001b[43mqlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_split\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(x_split, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal(x)\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\qnn\\torch.py:277\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    275\u001b[0m     reconstructor \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39munbind(inputs):\n\u001b[1;32m--> 277\u001b[0m         reconstructor\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(reconstructor)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# If the input is 1-dimensional, calculate the forward pass as usual\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\qnn\\torch.py:281\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(reconstructor)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# If the input is 1-dimensional, calculate the forward pass as usual\u001b[39;00m\n\u001b[1;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_qnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\qnn\\torch.py:296\u001b[0m, in \u001b[0;36mTorchLayer._evaluate_qnode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m\"\"\"Evaluates the QNode for a single input datapoint.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    tensor: output datapoint\u001b[39;00m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    292\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_arg: x},\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{arg: weight\u001b[38;5;241m.\u001b[39mto(x) \u001b[38;5;28;01mfor\u001b[39;00m arg, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode_weights\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[0;32m    295\u001b[0m }\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mtype(x\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\qnode.py:561\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# preprocess the tapes by applying any device-specific transforms\u001b[39;00m\n\u001b[0;32m    559\u001b[0m tapes, processing_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mbatch_transform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtape)\n\u001b[1;32m--> 561\u001b[0m res \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m    562\u001b[0m     tapes,\n\u001b[0;32m    563\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[0;32m    564\u001b[0m     gradient_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_fn,\n\u001b[0;32m    565\u001b[0m     interface\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterface,\n\u001b[0;32m    566\u001b[0m     gradient_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_kwargs,\n\u001b[0;32m    567\u001b[0m     override_shots\u001b[38;5;241m=\u001b[39moverride_shots,\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute_kwargs,\n\u001b[0;32m    569\u001b[0m )\n\u001b[0;32m    571\u001b[0m res \u001b[38;5;241m=\u001b[39m processing_fn(res)\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m override_shots \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;66;03m# restore the initialization gradient function\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\interfaces\\batch\\__init__.py:321\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(tapes, device, gradient_fn, interface, mode, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion)\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gradient_fn \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackprop\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m interface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcache_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_execute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# the default execution function is batch_execute\u001b[39;00m\n\u001b[0;32m    324\u001b[0m execute_fn \u001b[38;5;241m=\u001b[39m cache_execute(batch_execute, cache, expand_fn\u001b[38;5;241m=\u001b[39mexpand_fn)\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\interfaces\\batch\\__init__.py:168\u001b[0m, in \u001b[0;36mcache_execute.<locals>.wrapper\u001b[1;34m(tapes, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (res, []) \u001b[38;5;28;01mif\u001b[39;00m return_tuple \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# execute all unique tapes that do not exist in the cache\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m     res \u001b[38;5;241m=\u001b[39m fn(execution_tapes\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    170\u001b[0m final_res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tape \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tapes):\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\interfaces\\batch\\__init__.py:120\u001b[0m, in \u001b[0;36mcache_execute.<locals>.fn\u001b[1;34m(tapes, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(tapes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# pylint: disable=function-redefined\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     tapes \u001b[38;5;241m=\u001b[39m [expand_fn(tape) \u001b[38;5;28;01mfor\u001b[39;00m tape \u001b[38;5;129;01min\u001b[39;00m tapes]\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn(tapes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Program Files\\Python39\\lib\\contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\_qubit_device.py:278\u001b[0m, in \u001b[0;36mQubitDevice.batch_execute\u001b[1;34m(self, circuits)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m circuit \u001b[38;5;129;01min\u001b[39;00m circuits:\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;66;03m# we need to reset the device here, else it will\u001b[39;00m\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;66;03m# not start the next computation in the zero state\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m--> 278\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(res)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mactive:\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\devices\\default_qubit_torch.py:232\u001b[0m, in \u001b[0;36mDefaultQubitTorch.execute\u001b[1;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m params_cuda_device \u001b[38;5;241m!=\u001b[39m specified_device_cuda:\n\u001b[0;32m    225\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    226\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch device \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_torch_device\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m specified \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    227\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupon PennyLane device creation does not match the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch device of the gate parameters; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_torch_device\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m             )\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mexecute(circuit, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\_qubit_device.py:194\u001b[0m, in \u001b[0;36mQubitDevice.execute\u001b[1;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_validity(circuit\u001b[38;5;241m.\u001b[39moperations, circuit\u001b[38;5;241m.\u001b[39mobservables)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# apply all circuit operations\u001b[39;00m\n\u001b[1;32m--> 194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(circuit\u001b[38;5;241m.\u001b[39moperations, rotations\u001b[38;5;241m=\u001b[39mcircuit\u001b[38;5;241m.\u001b[39mdiagonalizing_gates, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# generate computational basis samples\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshots \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m circuit\u001b[38;5;241m.\u001b[39mis_sampled:\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\devices\\default_qubit.py:216\u001b[0m, in \u001b[0;36mDefaultQubit.apply\u001b[1;34m(self, operations, rotations, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_basis_state(operation\u001b[38;5;241m.\u001b[39mparameters[\u001b[38;5;241m0\u001b[39m], operation\u001b[38;5;241m.\u001b[39mwires)\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_operation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# store the pre-rotated state\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_rotated_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\devices\\default_qubit.py:247\u001b[0m, in \u001b[0;36mDefaultQubit._apply_operation\u001b[1;34m(self, state, operation)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_diagonal_unitary(state, matrix, wires)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(wires) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;66;03m# Einsum is faster for small gates\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_unitary_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwires\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_unitary(state, matrix, wires)\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pennylane\\devices\\default_qubit.py:752\u001b[0m, in \u001b[0;36mDefaultQubit._apply_unitary_einsum\u001b[1;34m(self, state, mat, wires)\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;66;03m# We now put together the indices in the notation numpy's einsum requires\u001b[39;00m\n\u001b[0;32m    750\u001b[0m einsum_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_indices\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00maffected_indices\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate_indices\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_state_indices\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43meinsum_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\torch\\functional.py:327\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;66;03m# recurse incase operands contains value that has torch function\u001b[39;00m\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;66;03m# in the original implementation this line is omitted\u001b[39;00m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "epochs, accuracy, loss = train(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1b08520f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 8.30\n",
      "Batch accuracy: 29.40\n",
      "Batch accuracy: 33.30\n",
      "Batch accuracy: 35.10\n",
      "Batch accuracy: 40.30\n",
      "Batch accuracy: 38.00\n",
      "Batch accuracy: 44.10\n",
      "Batch accuracy: 52.90\n",
      "Batch accuracy: 49.70\n",
      "Batch accuracy: 53.30\n",
      "Batch accuracy: 54.20\n",
      "Batch accuracy: 53.10\n",
      "Batch accuracy: 57.40\n",
      "Batch accuracy: 58.90\n",
      "Batch accuracy: 57.90\n",
      "Batch accuracy: 60.70\n",
      "Batch accuracy: 60.90\n",
      "Batch accuracy: 67.80\n",
      "Batch accuracy: 67.70\n",
      "Batch accuracy: 65.40\n",
      "Batch accuracy: 64.50\n",
      "Batch accuracy: 69.30\n",
      "Batch accuracy: 69.60\n",
      "Batch accuracy: 69.40\n",
      "Batch accuracy: 72.70\n",
      "Batch accuracy: 75.10\n",
      "Batch accuracy: 70.70\n",
      "Batch accuracy: 74.00\n",
      "Batch accuracy: 71.60\n",
      "Batch accuracy: 73.20\n",
      "Batch accuracy: 77.50\n",
      "Batch accuracy: 77.20\n",
      "Batch accuracy: 76.00\n",
      "Batch accuracy: 78.30\n",
      "Batch accuracy: 78.40\n",
      "Batch accuracy: 79.60\n",
      "Batch accuracy: 77.20\n",
      "Batch accuracy: 78.60\n",
      "Batch accuracy: 80.80\n",
      "Batch accuracy: 82.90\n",
      "Batch accuracy: 82.30\n",
      "Batch accuracy: 79.80\n",
      "Batch accuracy: 83.30\n",
      "Batch accuracy: 82.20\n",
      "Batch accuracy: 83.40\n",
      "Batch accuracy: 81.30\n",
      "Batch accuracy: 85.00\n",
      "Batch accuracy: 84.90\n",
      "Batch accuracy: 82.00\n",
      "Batch accuracy: 83.10\n",
      "Batch accuracy: 84.50\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 82.30\n",
      "Batch accuracy: 85.40\n",
      "Batch accuracy: 85.70\n",
      "Batch accuracy: 86.80\n",
      "Batch accuracy: 88.20\n",
      "Batch accuracy: 85.80\n",
      "Batch accuracy: 85.90\n",
      "Batch accuracy: 85.10\n",
      "Training accuracy: 69.49 \t Training loss: 111.65 \n",
      "Batch accuracy: 86.50\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 88.40\n",
      "Batch accuracy: 90.60\n",
      "Batch accuracy: 88.70\n",
      "Batch accuracy: 87.60\n",
      "Batch accuracy: 86.80\n",
      "Batch accuracy: 86.80\n",
      "Batch accuracy: 88.50\n",
      "Batch accuracy: 88.60\n",
      "Batch accuracy: 88.90\n",
      "Batch accuracy: 87.80\n",
      "Batch accuracy: 88.20\n",
      "Batch accuracy: 89.70\n",
      "Batch accuracy: 89.40\n",
      "Batch accuracy: 90.60\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 89.00\n",
      "Batch accuracy: 90.00\n",
      "Batch accuracy: 89.70\n",
      "Batch accuracy: 90.70\n",
      "Batch accuracy: 90.40\n",
      "Batch accuracy: 90.50\n",
      "Batch accuracy: 89.90\n",
      "Batch accuracy: 91.90\n",
      "Batch accuracy: 89.90\n",
      "Batch accuracy: 90.00\n",
      "Batch accuracy: 90.80\n",
      "Batch accuracy: 88.60\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 90.50\n",
      "Batch accuracy: 92.20\n",
      "Batch accuracy: 88.90\n",
      "Batch accuracy: 90.60\n",
      "Batch accuracy: 92.40\n",
      "Batch accuracy: 90.40\n",
      "Batch accuracy: 91.50\n",
      "Batch accuracy: 91.70\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 91.90\n",
      "Batch accuracy: 91.70\n",
      "Batch accuracy: 92.50\n",
      "Batch accuracy: 90.30\n",
      "Batch accuracy: 91.10\n",
      "Batch accuracy: 92.10\n",
      "Batch accuracy: 91.90\n",
      "Batch accuracy: 93.40\n",
      "Batch accuracy: 93.50\n",
      "Batch accuracy: 92.00\n",
      "Batch accuracy: 91.90\n",
      "Batch accuracy: 91.00\n",
      "Batch accuracy: 91.40\n",
      "Batch accuracy: 92.90\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 92.70\n",
      "Batch accuracy: 91.50\n",
      "Batch accuracy: 91.70\n",
      "Batch accuracy: 91.90\n",
      "Batch accuracy: 91.40\n",
      "Batch accuracy: 91.70\n",
      "Training accuracy: 90.42 \t Training loss: 103.77 \n",
      "Batch accuracy: 93.50\n",
      "Batch accuracy: 94.80\n",
      "Batch accuracy: 92.80\n",
      "Batch accuracy: 93.10\n",
      "Batch accuracy: 93.90\n",
      "Batch accuracy: 92.40\n",
      "Batch accuracy: 92.80\n",
      "Batch accuracy: 92.20\n",
      "Batch accuracy: 91.70\n",
      "Batch accuracy: 93.30\n",
      "Batch accuracy: 94.40\n",
      "Batch accuracy: 95.30\n",
      "Batch accuracy: 95.30\n",
      "Batch accuracy: 94.30\n",
      "Batch accuracy: 93.40\n",
      "Batch accuracy: 94.00\n",
      "Batch accuracy: 92.40\n",
      "Batch accuracy: 93.80\n",
      "Batch accuracy: 93.20\n",
      "Batch accuracy: 94.30\n",
      "Batch accuracy: 93.80\n",
      "Batch accuracy: 94.20\n",
      "Batch accuracy: 94.50\n",
      "Batch accuracy: 93.90\n",
      "Batch accuracy: 93.70\n",
      "Batch accuracy: 94.20\n",
      "Batch accuracy: 94.40\n",
      "Batch accuracy: 92.80\n",
      "Batch accuracy: 95.50\n",
      "Batch accuracy: 93.10\n",
      "Batch accuracy: 94.80\n",
      "Batch accuracy: 93.80\n",
      "Batch accuracy: 93.60\n",
      "Batch accuracy: 93.80\n",
      "Batch accuracy: 93.80\n",
      "Batch accuracy: 94.00\n",
      "Batch accuracy: 93.90\n",
      "Batch accuracy: 93.20\n",
      "Batch accuracy: 92.90\n",
      "Batch accuracy: 93.10\n",
      "Batch accuracy: 94.20\n",
      "Batch accuracy: 94.60\n",
      "Batch accuracy: 94.40\n",
      "Batch accuracy: 95.30\n",
      "Batch accuracy: 93.30\n",
      "Batch accuracy: 94.00\n",
      "Batch accuracy: 94.50\n",
      "Batch accuracy: 95.80\n",
      "Batch accuracy: 93.40\n",
      "Batch accuracy: 92.50\n",
      "Batch accuracy: 93.20\n",
      "Batch accuracy: 93.10\n",
      "Batch accuracy: 93.50\n",
      "Batch accuracy: 93.30\n",
      "Batch accuracy: 94.00\n",
      "Batch accuracy: 92.70\n",
      "Batch accuracy: 94.30\n",
      "Batch accuracy: 94.60\n",
      "Batch accuracy: 94.00\n",
      "Batch accuracy: 94.20\n",
      "Training accuracy: 93.78 \t Training loss: 102.26 \n",
      "Batch accuracy: 94.00\n",
      "Batch accuracy: 95.90\n",
      "Batch accuracy: 95.80\n",
      "Batch accuracy: 95.30\n",
      "Batch accuracy: 95.10\n",
      "Batch accuracy: 95.70\n",
      "Batch accuracy: 94.90\n",
      "Batch accuracy: 94.50\n",
      "Batch accuracy: 95.60\n",
      "Batch accuracy: 95.90\n",
      "Batch accuracy: 93.80\n",
      "Batch accuracy: 95.00\n",
      "Batch accuracy: 94.80\n",
      "Batch accuracy: 93.90\n",
      "Batch accuracy: 95.30\n",
      "Batch accuracy: 94.70\n",
      "Batch accuracy: 94.40\n",
      "Batch accuracy: 96.40\n",
      "Batch accuracy: 94.60\n",
      "Batch accuracy: 95.50\n",
      "Batch accuracy: 94.30\n",
      "Batch accuracy: 94.80\n",
      "Batch accuracy: 95.60\n",
      "Batch accuracy: 95.70\n",
      "Batch accuracy: 94.70\n",
      "Batch accuracy: 95.60\n",
      "Batch accuracy: 94.40\n",
      "Batch accuracy: 94.50\n",
      "Batch accuracy: 94.70\n",
      "Batch accuracy: 95.60\n",
      "Batch accuracy: 94.20\n",
      "Batch accuracy: 95.50\n",
      "Batch accuracy: 94.50\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 95.50\n",
      "Batch accuracy: 94.30\n",
      "Batch accuracy: 95.00\n",
      "Batch accuracy: 95.10\n",
      "Batch accuracy: 95.30\n",
      "Batch accuracy: 95.50\n",
      "Batch accuracy: 95.10\n",
      "Batch accuracy: 95.70\n",
      "Batch accuracy: 95.60\n",
      "Batch accuracy: 95.60\n",
      "Batch accuracy: 94.50\n",
      "Batch accuracy: 95.20\n",
      "Batch accuracy: 95.00\n",
      "Batch accuracy: 94.80\n",
      "Batch accuracy: 96.20\n",
      "Batch accuracy: 96.00\n",
      "Batch accuracy: 96.00\n",
      "Batch accuracy: 94.60\n",
      "Batch accuracy: 95.10\n",
      "Batch accuracy: 95.60\n",
      "Batch accuracy: 94.40\n",
      "Batch accuracy: 96.20\n",
      "Batch accuracy: 95.80\n",
      "Batch accuracy: 94.60\n",
      "Batch accuracy: 94.50\n",
      "Batch accuracy: 95.00\n",
      "Training accuracy: 95.14 \t Training loss: 101.61 \n",
      "Batch accuracy: 95.60\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 95.70\n",
      "Batch accuracy: 94.80\n",
      "Batch accuracy: 95.30\n",
      "Batch accuracy: 95.60\n",
      "Batch accuracy: 95.70\n",
      "Batch accuracy: 95.20\n",
      "Batch accuracy: 96.00\n",
      "Batch accuracy: 95.90\n",
      "Batch accuracy: 96.30\n",
      "Batch accuracy: 95.40\n",
      "Batch accuracy: 95.60\n",
      "Batch accuracy: 96.10\n",
      "Batch accuracy: 96.30\n",
      "Batch accuracy: 96.10\n",
      "Batch accuracy: 96.40\n",
      "Batch accuracy: 95.30\n",
      "Batch accuracy: 95.70\n",
      "Batch accuracy: 96.60\n",
      "Batch accuracy: 96.30\n",
      "Batch accuracy: 95.60\n",
      "Batch accuracy: 96.00\n",
      "Batch accuracy: 95.60\n",
      "Batch accuracy: 95.30\n",
      "Batch accuracy: 96.10\n",
      "Batch accuracy: 95.50\n",
      "Batch accuracy: 95.50\n",
      "Batch accuracy: 96.10\n",
      "Batch accuracy: 95.20\n",
      "Batch accuracy: 96.00\n",
      "Batch accuracy: 94.90\n",
      "Batch accuracy: 96.40\n",
      "Batch accuracy: 96.40\n",
      "Batch accuracy: 94.80\n",
      "Batch accuracy: 94.80\n",
      "Batch accuracy: 94.90\n",
      "Batch accuracy: 95.80\n",
      "Batch accuracy: 94.80\n",
      "Batch accuracy: 96.00\n",
      "Batch accuracy: 96.50\n",
      "Batch accuracy: 96.20\n",
      "Batch accuracy: 96.50\n",
      "Batch accuracy: 95.50\n",
      "Batch accuracy: 96.50\n",
      "Batch accuracy: 95.90\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 95.40\n",
      "Batch accuracy: 95.60\n",
      "Batch accuracy: 95.10\n",
      "Batch accuracy: 95.90\n",
      "Batch accuracy: 95.00\n",
      "Batch accuracy: 96.50\n",
      "Batch accuracy: 96.00\n",
      "Batch accuracy: 95.50\n",
      "Batch accuracy: 95.50\n",
      "Batch accuracy: 95.70\n",
      "Batch accuracy: 96.50\n",
      "Batch accuracy: 96.00\n",
      "Batch accuracy: 95.90\n",
      "Training accuracy: 95.79 \t Training loss: 101.29 \n",
      "Batch accuracy: 97.40\n",
      "Batch accuracy: 95.80\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 96.00\n",
      "Batch accuracy: 95.20\n",
      "Batch accuracy: 96.20\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 96.20\n",
      "Batch accuracy: 96.10\n",
      "Batch accuracy: 96.20\n",
      "Batch accuracy: 95.60\n",
      "Batch accuracy: 95.40\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 96.10\n",
      "Batch accuracy: 96.60\n",
      "Batch accuracy: 96.50\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 95.60\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 95.30\n",
      "Batch accuracy: 95.00\n",
      "Batch accuracy: 96.40\n",
      "Batch accuracy: 95.20\n",
      "Batch accuracy: 96.20\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 95.20\n",
      "Batch accuracy: 95.90\n",
      "Batch accuracy: 96.50\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 97.40\n",
      "Batch accuracy: 96.20\n",
      "Batch accuracy: 96.40\n",
      "Batch accuracy: 96.40\n",
      "Batch accuracy: 96.60\n",
      "Batch accuracy: 95.40\n",
      "Batch accuracy: 94.20\n",
      "Batch accuracy: 95.40\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 95.60\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 96.30\n",
      "Batch accuracy: 96.00\n",
      "Batch accuracy: 96.40\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 95.90\n",
      "Batch accuracy: 95.90\n",
      "Batch accuracy: 96.60\n",
      "Batch accuracy: 96.00\n",
      "Batch accuracy: 95.50\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 95.10\n",
      "Batch accuracy: 95.90\n",
      "Training accuracy: 96.27 \t Training loss: 101.04 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 96.00\n",
      "Batch accuracy: 96.30\n",
      "Batch accuracy: 95.80\n",
      "Batch accuracy: 96.10\n",
      "Batch accuracy: 97.60\n",
      "Batch accuracy: 97.10\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 96.90\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 96.50\n",
      "Batch accuracy: 97.60\n",
      "Batch accuracy: 96.30\n",
      "Batch accuracy: 97.70\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 96.40\n",
      "Batch accuracy: 96.90\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 96.20\n",
      "Batch accuracy: 97.10\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 96.60\n",
      "Batch accuracy: 98.00\n",
      "Batch accuracy: 95.90\n",
      "Batch accuracy: 96.40\n",
      "Batch accuracy: 95.50\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 96.40\n",
      "Batch accuracy: 97.90\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 97.10\n",
      "Batch accuracy: 96.20\n",
      "Batch accuracy: 96.90\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 96.90\n",
      "Batch accuracy: 96.40\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 96.30\n",
      "Batch accuracy: 95.30\n",
      "Batch accuracy: 96.60\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 96.10\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 96.00\n",
      "Batch accuracy: 95.70\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 96.10\n",
      "Batch accuracy: 96.60\n",
      "Batch accuracy: 95.70\n",
      "Batch accuracy: 96.70\n",
      "Training accuracy: 96.71 \t Training loss: 100.82 \n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 96.40\n",
      "Batch accuracy: 96.90\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 98.40\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 96.20\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 98.10\n",
      "Batch accuracy: 97.70\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 97.10\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 97.10\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 96.60\n",
      "Batch accuracy: 96.10\n",
      "Batch accuracy: 97.10\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 97.10\n",
      "Batch accuracy: 97.10\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 97.60\n",
      "Batch accuracy: 96.00\n",
      "Batch accuracy: 96.60\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 96.20\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 97.40\n",
      "Batch accuracy: 98.10\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 96.50\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 96.50\n",
      "Batch accuracy: 97.70\n",
      "Batch accuracy: 97.40\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 96.60\n",
      "Batch accuracy: 95.90\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 97.10\n",
      "Batch accuracy: 96.90\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 97.70\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 96.40\n",
      "Batch accuracy: 96.30\n",
      "Batch accuracy: 96.10\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 96.40\n",
      "Training accuracy: 96.98 \t Training loss: 100.70 \n",
      "Batch accuracy: 98.00\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 97.90\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 97.40\n",
      "Batch accuracy: 97.40\n",
      "Batch accuracy: 97.80\n",
      "Batch accuracy: 97.80\n",
      "Batch accuracy: 97.10\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 96.50\n",
      "Batch accuracy: 98.10\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 97.80\n",
      "Batch accuracy: 95.90\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 97.70\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 97.80\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 97.10\n",
      "Batch accuracy: 97.40\n",
      "Batch accuracy: 97.40\n",
      "Batch accuracy: 97.90\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 96.90\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 97.90\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 96.40\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 96.30\n",
      "Batch accuracy: 98.60\n",
      "Batch accuracy: 95.70\n",
      "Batch accuracy: 97.60\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 95.90\n",
      "Batch accuracy: 97.40\n",
      "Batch accuracy: 96.30\n",
      "Batch accuracy: 96.20\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 97.10\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 96.50\n",
      "Batch accuracy: 98.00\n",
      "Batch accuracy: 96.90\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 97.10\n",
      "Batch accuracy: 97.60\n",
      "Batch accuracy: 98.00\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 97.40\n",
      "Training accuracy: 97.21 \t Training loss: 100.59 \n",
      "Batch accuracy: 97.40\n",
      "Batch accuracy: 98.20\n",
      "Batch accuracy: 96.90\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 97.60\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 97.80\n",
      "Batch accuracy: 98.10\n",
      "Batch accuracy: 97.60\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 96.60\n",
      "Batch accuracy: 98.00\n",
      "Batch accuracy: 98.10\n",
      "Batch accuracy: 97.70\n",
      "Batch accuracy: 96.90\n",
      "Batch accuracy: 96.10\n",
      "Batch accuracy: 98.50\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 97.40\n",
      "Batch accuracy: 96.50\n",
      "Batch accuracy: 97.00\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 97.80\n",
      "Batch accuracy: 97.90\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 97.20\n",
      "Batch accuracy: 97.10\n",
      "Batch accuracy: 97.90\n",
      "Batch accuracy: 97.40\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 97.90\n",
      "Batch accuracy: 98.40\n",
      "Batch accuracy: 97.70\n",
      "Batch accuracy: 97.70\n",
      "Batch accuracy: 96.30\n",
      "Batch accuracy: 97.40\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 97.60\n",
      "Batch accuracy: 97.60\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 95.80\n",
      "Batch accuracy: 96.90\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 96.80\n",
      "Batch accuracy: 95.90\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 98.10\n",
      "Batch accuracy: 97.50\n",
      "Batch accuracy: 97.10\n",
      "Batch accuracy: 96.70\n",
      "Batch accuracy: 97.30\n",
      "Batch accuracy: 96.90\n",
      "Batch accuracy: 98.10\n",
      "Training accuracy: 97.33 \t Training loss: 100.51 \n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "epochs, accuracy, loss = train(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f4cf3464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2972882bd30>]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c48639",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b76ece",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cadf05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(): \n",
    "    accuracy = 0\n",
    "    with torch.no_grad(): \n",
    "        for image, labels in enumerate(test_dataloader): \n",
    "            output = network(image)\n",
    "            predicted = torch.max(output.data, 1)[1]\n",
    "            accuracy += (100*(predicted == labels).sum() / len(labels))\n",
    "    print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde859be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a11a1f8",
   "metadata": {},
   "source": [
    "# Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca0c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b9b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd069e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd58fbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e393f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba912c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = [] \n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abde6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 10\n",
    "\n",
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            torch.save(network.state_dict(), '/results/model.pth')\n",
    "            torch.save(optimizer.state_dict(), '/results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65e00b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "773ec097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew Hayman\\AppData\\Local\\Temp\\ipykernel_520\\161431047.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3063, Accuracy: 1377/10000 (14%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.312027\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/results/model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m test()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     test()\n",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     15\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     16\u001b[0m train_counter\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     17\u001b[0m     (batch_idx\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m64\u001b[39m) \u001b[38;5;241m+\u001b[39m ((epoch\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset)))\n\u001b[1;32m---> 18\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/results/model.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(optimizer\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/results/optimizer.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\torch\\serialization.py:376\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \n\u001b[0;32m    342\u001b[0m \u001b[38;5;124;03mSaves an object to a disk file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    374\u001b[0m _check_dill_version(pickle_module)\n\u001b[1;32m--> 376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    378\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/results/model.pth'"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2702ff91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
