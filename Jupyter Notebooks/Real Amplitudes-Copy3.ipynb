{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d093a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew Hayman\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\Andrew Hayman\\PycharmProjects\\Hybrid_Network_Models\\venv\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cca78b",
   "metadata": {},
   "source": [
    "# MNIST Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8512c0",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4405ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from MNIST dataset \n",
    "training_data = torchvision.datasets.MNIST(\"root\", train=True, download=True, transform=ToTensor())\n",
    "testing_data = torchvision.datasets.MNIST(\"root\", train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "860f6baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only do 0's and 1's\n",
    "#training_data.data = training_data.data[training_data.targets<=1]\n",
    "#training_data.targets = training_data.targets[training_data.targets<=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca0e3aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:\t  torch.Size([60000, 28, 28])\n",
      "Testing data size:\t  torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Display information on datasets\n",
    "print(\"Training data size:\\t \", training_data.data.size())\n",
    "print(\"Testing data size:\\t \", testing_data.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c3f747e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '5')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a sample\n",
    "plt.imshow(training_data.data[0])\n",
    "plt.title('%i' % training_data.targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f43abb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare subset of data and shuffle\n",
    "train_dataloader = DataLoader(training_data, batch_size = 500, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_data, batch_size = 100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc4536d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 784])\n",
      "torch.Size([500])\n"
     ]
    }
   ],
   "source": [
    "# Showcase dataloader information\n",
    "for batch, (images, labels) in enumerate(train_dataloader): \n",
    "    print(batch)\n",
    "    print(images.size())\n",
    "    print(images.view(images.shape[0], -1).size())\n",
    "    print(labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5534746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "test = torch.nn.functional.one_hot(training_data.targets)\n",
    "print(test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2b0808",
   "metadata": {},
   "source": [
    "## Network Design and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51bc13b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9248, -0.0444, -0.5679], grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubits = 3\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "dev = qml.device(\"projectq.simulator\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def qnode_3_amplitudes(inputs, weights):\n",
    "    \n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.Hadamard(wires=1)\n",
    "    qml.Hadamard(wires=2)\n",
    "    \n",
    "    qml.RY(inputs[0], wires=0)\n",
    "    qml.RY(inputs[1], wires=1)\n",
    "    qml.RY(inputs[2], wires=2)\n",
    "    \n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[0, 2])\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    \n",
    "    qml.RY(weights[0], wires=0)\n",
    "    qml.RY(weights[1], wires=1)\n",
    "    qml.RY(weights[2], wires=2)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2))\n",
    "\n",
    "weight_shapes = {\"weights\": 3}\n",
    "qlayer_3_amplitudes = qml.qnn.TorchLayer(qnode_3_amplitudes, weight_shapes)\n",
    "\n",
    "qlayer_3_amplitudes(torch.Tensor([1,3,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc57fce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew Hayman\\PycharmProjects\\Hybrid_Network_Models\\venv\\lib\\site-packages\\pyquil\\api\\_compiler.py:480: UserWarning: Request to quilc at tcp://127.0.0.1:5555 timed out. This could mean that quilc is not running, is not reachable, or is responding slowly.. Compilation using quilc will not be available.\n",
      "  warnings.warn(f\"{e}. Compilation using quilc will not be available.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3180,  0.5340, -0.5940,  0.4340], grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubits = 4\n",
    "#dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "dev = qml.device(\"forest.qvm\", device=\"{}q-pyqvm\".format(n_qubits))\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def qnode_4_amplitudes(inputs, weights):\n",
    "    \n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.Hadamard(wires=1)\n",
    "    qml.Hadamard(wires=2)\n",
    "    qml.Hadamard(wires=3)\n",
    "    \n",
    "    qml.RY(inputs[0], wires=0)\n",
    "    qml.RY(inputs[1], wires=1)\n",
    "    qml.RY(inputs[2], wires=2)\n",
    "    qml.RY(inputs[3], wires=3)\n",
    "    \n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[0, 2])\n",
    "    qml.CNOT(wires=[0, 3])\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    qml.CNOT(wires=[1, 3])\n",
    "    qml.CNOT(wires=[2, 3])\n",
    "    \n",
    "    qml.RY(weights[0], wires=0)\n",
    "    qml.RY(weights[1], wires=1)\n",
    "    qml.RY(weights[2], wires=2)\n",
    "    qml.RY(weights[3], wires=3)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2)), qml.expval(qml.PauliZ(3))\n",
    "\n",
    "weight_shapes = {\"weights\": 4}\n",
    "qlayer_4_amplitudes = qml.qnn.TorchLayer(qnode_4_amplitudes, weight_shapes)\n",
    "\n",
    "qlayer_4_amplitudes(torch.Tensor([1,3,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d084442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8413,  0.0076, -0.0107, -0.0928,  0.3605],\n",
       "       grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubits = 5\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def qnode_5_amplitudes(inputs, weights):\n",
    "    \n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.Hadamard(wires=1)\n",
    "    qml.Hadamard(wires=2)\n",
    "    qml.Hadamard(wires=3)\n",
    "    qml.Hadamard(wires=4)\n",
    "    \n",
    "    qml.RY(inputs[0], wires=0)\n",
    "    qml.RY(inputs[1], wires=1)\n",
    "    qml.RY(inputs[2], wires=2)\n",
    "    qml.RY(inputs[3], wires=3)\n",
    "    qml.RY(inputs[4], wires=4)\n",
    "    \n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[0, 2])\n",
    "    qml.CNOT(wires=[0, 3])\n",
    "    qml.CNOT(wires=[0, 4])\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    qml.CNOT(wires=[1, 3])\n",
    "    qml.CNOT(wires=[1, 4])\n",
    "    qml.CNOT(wires=[2, 3])\n",
    "    qml.CNOT(wires=[2, 4])\n",
    "    qml.CNOT(wires=[3, 4])\n",
    "    \n",
    "    qml.RY(weights[0], wires=0)\n",
    "    qml.RY(weights[1], wires=1)\n",
    "    qml.RY(weights[2], wires=2)\n",
    "    qml.RY(weights[3], wires=3)\n",
    "    qml.RY(weights[4], wires=4)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2)), qml.expval(qml.PauliZ(3)), qml.expval(qml.PauliZ(4))\n",
    "\n",
    "weight_shapes = {\"weights\": 5}\n",
    "qlayer_5_amplitudes = qml.qnn.TorchLayer(qnode_5_amplitudes, weight_shapes)\n",
    "\n",
    "qlayer_5_amplitudes(torch.Tensor([1,3,3,5,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eea76937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "(0, 1, 2)\n",
      "(0, 1, 3)\n",
      "(0, 1, 4)\n",
      "(0, 1, 5)\n",
      "(0, 1, 6)\n",
      "(0, 1, 7)\n",
      "(0, 1, 8)\n",
      "(0, 1, 9)\n",
      "(0, 2, 3)\n",
      "(0, 2, 4)\n",
      "(0, 2, 5)\n",
      "(0, 2, 6)\n",
      "(0, 2, 7)\n",
      "(0, 2, 8)\n",
      "(0, 2, 9)\n",
      "(0, 3, 4)\n",
      "(0, 3, 5)\n",
      "(0, 3, 6)\n",
      "(0, 3, 7)\n",
      "(0, 3, 8)\n",
      "(0, 3, 9)\n",
      "(0, 4, 5)\n",
      "(0, 4, 6)\n",
      "(0, 4, 7)\n",
      "(0, 4, 8)\n",
      "(0, 4, 9)\n",
      "(0, 5, 6)\n",
      "(0, 5, 7)\n",
      "(0, 5, 8)\n",
      "(0, 5, 9)\n",
      "(0, 6, 7)\n",
      "(0, 6, 8)\n",
      "(0, 6, 9)\n",
      "(0, 7, 8)\n",
      "(0, 7, 9)\n",
      "(0, 8, 9)\n",
      "(1, 2, 3)\n",
      "(1, 2, 4)\n",
      "(1, 2, 5)\n",
      "(1, 2, 6)\n",
      "(1, 2, 7)\n",
      "(1, 2, 8)\n",
      "(1, 2, 9)\n",
      "(1, 3, 4)\n",
      "(1, 3, 5)\n",
      "(1, 3, 6)\n",
      "(1, 3, 7)\n",
      "(1, 3, 8)\n",
      "(1, 3, 9)\n",
      "(1, 4, 5)\n",
      "(1, 4, 6)\n",
      "(1, 4, 7)\n",
      "(1, 4, 8)\n",
      "(1, 4, 9)\n",
      "(1, 5, 6)\n",
      "(1, 5, 7)\n",
      "(1, 5, 8)\n",
      "(1, 5, 9)\n",
      "(1, 6, 7)\n",
      "(1, 6, 8)\n",
      "(1, 6, 9)\n",
      "(1, 7, 8)\n",
      "(1, 7, 9)\n",
      "(1, 8, 9)\n",
      "(2, 3, 4)\n",
      "(2, 3, 5)\n",
      "(2, 3, 6)\n",
      "(2, 3, 7)\n",
      "(2, 3, 8)\n",
      "(2, 3, 9)\n",
      "(2, 4, 5)\n",
      "(2, 4, 6)\n",
      "(2, 4, 7)\n",
      "(2, 4, 8)\n",
      "(2, 4, 9)\n",
      "(2, 5, 6)\n",
      "(2, 5, 7)\n",
      "(2, 5, 8)\n",
      "(2, 5, 9)\n",
      "(2, 6, 7)\n",
      "(2, 6, 8)\n",
      "(2, 6, 9)\n",
      "(2, 7, 8)\n",
      "(2, 7, 9)\n",
      "(2, 8, 9)\n",
      "(3, 4, 5)\n",
      "(3, 4, 6)\n",
      "(3, 4, 7)\n",
      "(3, 4, 8)\n",
      "(3, 4, 9)\n",
      "(3, 5, 6)\n",
      "(3, 5, 7)\n",
      "(3, 5, 8)\n",
      "(3, 5, 9)\n",
      "(3, 6, 7)\n",
      "(3, 6, 8)\n",
      "(3, 6, 9)\n",
      "(3, 7, 8)\n",
      "(3, 7, 9)\n",
      "(3, 8, 9)\n",
      "(4, 5, 6)\n",
      "(4, 5, 7)\n",
      "(4, 5, 8)\n",
      "(4, 5, 9)\n",
      "(4, 6, 7)\n",
      "(4, 6, 8)\n",
      "(4, 6, 9)\n",
      "(4, 7, 8)\n",
      "(4, 7, 9)\n",
      "(4, 8, 9)\n",
      "(5, 6, 7)\n",
      "(5, 6, 8)\n",
      "(5, 6, 9)\n",
      "(5, 7, 8)\n",
      "(5, 7, 9)\n",
      "(5, 8, 9)\n",
      "(6, 7, 8)\n",
      "(6, 7, 9)\n",
      "(6, 8, 9)\n",
      "(7, 8, 9)\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "lst = list(range(0,10))\n",
    "print(lst)\n",
    "i=0\n",
    "for combo in combinations( list(range(0,10)), 3): \n",
    "    print(combo)\n",
    "    i +=1\n",
    "    \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8ef4614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network \n",
    "# Great source: https://pennylane.ai/qml/demos/tutorial_qnn_module_torch.html\n",
    "# Note that in_channels = 1 because the input is a grayscale image\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(in_features=784, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=10),\n",
    "        )\n",
    "        \n",
    "        self.final = nn.Sequential(nn.Linear(in_features=360, out_features=64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(in_features=64, out_features=10),\n",
    "                                    nn.LogSoftmax(dim=1))\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.main(x)\n",
    "        x_split = torch.split(x, 1, dim=1)\n",
    "        x_split = list(x_split)\n",
    "\n",
    "        x_out = []\n",
    "        \n",
    "        i=0\n",
    "        for combo in combinations(list(range(0,10)), 3):\n",
    "            i+=1\n",
    "            print(\"combo\", i)\n",
    "            x_temp = torch.cat([x_split[combo[0]], x_split[combo[1]], x_split[combo[2]]], dim=1)\n",
    "            x_temp = qlayer_3_amplitudes(x_temp)\n",
    "            x_out.append(x_temp)\n",
    "        \n",
    "        x = torch.cat(x_out, dim=1)\n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0a602f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View neural network \n",
    "model = Net()\n",
    "#test = training_data.data[0:100]\n",
    "#test = test.view(-1, 784)\n",
    "#test = test/2.0\n",
    "#y = model.forward(test)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd8c84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchsummary import summary\n",
    "#summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a80de6",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b3e5409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training routine\n",
    "import time\n",
    "\n",
    "def train(epochs):\n",
    "    epoch_list = []\n",
    "    accuracy_list = []\n",
    "    loss_list = []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        accuracy = 0\n",
    "        running_loss = 0\n",
    "\n",
    "        for batch_idx, (image, labels) in enumerate(train_dataloader):\n",
    "            start = time.time()\n",
    "            output = model(image)                           # Find network output\n",
    "            loss = loss_function(output, labels)              # Compute loss\n",
    "\n",
    "            predicted = torch.max(output.data, 1)[1]          # Find predicted value\n",
    "            batch_corr = (predicted == labels).sum()          # Find number of correct values\n",
    "            batch_accuracy = (100*batch_corr / len(labels))    \n",
    "            accuracy+=batch_accuracy/120\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()                             # Clear gradients for this training step\n",
    "            loss.backward()                                   # Compute gradients from backpropagation \n",
    "            optimizer.step()                                  # Apply changes from gradients\n",
    "            end = time.time()\n",
    "            print(\"Batch accuracy: %.2f Time: %.2f\" % (batch_accuracy, (end - start)))\n",
    "\n",
    "        print(\"Training accuracy: %.2f \\t Training loss: %.2f \" % (accuracy, running_loss))\n",
    "        epoch_list.append(epoch)\n",
    "        accuracy_list.append(accuracy)\n",
    "        loss_list.append(running_loss)\n",
    "    return epoch_list, accuracy_list, loss_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc77c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combo 1\n",
      "combo 2\n",
      "combo 3\n",
      "combo 4\n",
      "combo 5\n",
      "combo 6\n",
      "combo 7\n",
      "combo 8\n",
      "combo 9\n",
      "combo 10\n",
      "combo 11\n",
      "combo 12\n",
      "combo 13\n",
      "combo 14\n",
      "combo 15\n",
      "combo 16\n",
      "combo 17\n",
      "combo 18\n",
      "combo 19\n",
      "combo 20\n",
      "combo 21\n",
      "combo 22\n",
      "combo 23\n",
      "combo 24\n",
      "combo 25\n",
      "combo 26\n",
      "combo 27\n",
      "combo 28\n",
      "combo 29\n",
      "combo 30\n",
      "combo 31\n",
      "combo 32\n",
      "combo 33\n",
      "combo 34\n",
      "combo 35\n",
      "combo 36\n",
      "combo 37\n",
      "combo 38\n",
      "combo 39\n",
      "combo 40\n",
      "combo 41\n",
      "combo 42\n",
      "combo 43\n",
      "combo 44\n",
      "combo 45\n",
      "combo 46\n",
      "combo 47\n",
      "combo 48\n",
      "combo 49\n",
      "combo 50\n",
      "combo 51\n",
      "combo 52\n",
      "combo 53\n",
      "combo 54\n",
      "combo 55\n",
      "combo 56\n",
      "combo 57\n",
      "combo 58\n",
      "combo 59\n",
      "combo 60\n",
      "combo 61\n",
      "combo 62\n",
      "combo 63\n",
      "combo 64\n",
      "combo 65\n",
      "combo 66\n",
      "combo 67\n",
      "combo 68\n",
      "combo 69\n",
      "combo 70\n",
      "combo 71\n",
      "combo 72\n",
      "combo 73\n",
      "combo 74\n",
      "combo 75\n",
      "combo 76\n",
      "combo 77\n",
      "combo 78\n",
      "combo 79\n",
      "combo 80\n",
      "combo 81\n",
      "combo 82\n",
      "combo 83\n",
      "combo 84\n",
      "combo 85\n",
      "combo 86\n",
      "combo 87\n",
      "combo 88\n",
      "combo 89\n",
      "combo 90\n",
      "combo 91\n",
      "combo 92\n",
      "combo 93\n",
      "combo 94\n",
      "combo 95\n",
      "combo 96\n",
      "combo 97\n",
      "combo 98\n",
      "combo 99\n",
      "combo 100\n",
      "combo 101\n",
      "combo 102\n",
      "combo 103\n",
      "combo 104\n",
      "combo 105\n",
      "combo 106\n",
      "combo 107\n",
      "combo 108\n",
      "combo 109\n",
      "combo 110\n",
      "combo 111\n",
      "combo 112\n",
      "combo 113\n",
      "combo 114\n",
      "combo 115\n",
      "combo 116\n",
      "combo 117\n",
      "combo 118\n",
      "combo 119\n",
      "combo 120\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "epochs, accuracy, loss = train(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cf3464",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c48639",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b76ece",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cadf05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(): \n",
    "    accuracy = 0\n",
    "    with torch.no_grad(): \n",
    "        for image, labels in enumerate(test_dataloader): \n",
    "            output = network(image)\n",
    "            predicted = torch.max(output.data, 1)[1]\n",
    "            accuracy += (100*(predicted == labels).sum() / len(labels))\n",
    "    print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde859be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a11a1f8",
   "metadata": {},
   "source": [
    "# Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca0c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b9b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd069e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd58fbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e393f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba912c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = [] \n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 10\n",
    "\n",
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            torch.save(network.state_dict(), '/results/model.pth')\n",
    "            torch.save(optimizer.state_dict(), '/results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e00b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ec097",
   "metadata": {},
   "outputs": [],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2702ff91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
